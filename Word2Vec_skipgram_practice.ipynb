{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOOHbgdESO9r6u005h5m7bM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fizzyf0xy/NLP/blob/main/Word2Vec_skipgram_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec"
      ],
      "metadata": {
        "id": "JA9fufDPbKFJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "pNc1v3ajKY7i"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.__version__, torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXP4AEtNbM0S",
        "outputId": "b1b37758-afcf-452b-b343-29e7577b3725"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.22.4', '1.13.1+cu116')"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "matplotlib.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "x8AvnklPboHg",
        "outputId": "7de8565e-ebe8-4d00-adfe-1654dbcec927"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.5.3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Load the data"
      ],
      "metadata": {
        "id": "fB9njdCDbt9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#specify the sentences / corpus\n",
        "#corpus is defined as a set of documents\n",
        "#document is basically a bunch of sentence(s)\n",
        "corpus = [\"apple banana fruit\", \"banana apple fruit\", \"banana fruit apple\", \n",
        "          \"dog cat animal\", \"cat dog animal\", \"cat animal dog\"]"
      ],
      "metadata": {
        "id": "9yYeQHvWbqxg"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1. tokenize\n",
        "#usually you use spaCy / NLTK to tokenize (but we gonna do this later on, we gonna have spaCy)\n",
        "corpus_tokenized = [sent.split(\" \") for sent in corpus]\n",
        "corpus_tokenized  #we called each of this as \"tokens\", NOT words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ysspt21b0s-",
        "outputId": "5c3b7d93-8765-47d1-94e9-8b29657153ed"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['apple', 'banana', 'fruit'],\n",
              " ['banana', 'apple', 'fruit'],\n",
              " ['banana', 'fruit', 'apple'],\n",
              " ['dog', 'cat', 'animal'],\n",
              " ['cat', 'dog', 'animal'],\n",
              " ['cat', 'animal', 'dog']]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. numericalize\n",
        "\n",
        "#2.1 get all the unique words\n",
        "#we want to flatten this (basically merge all list)\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "vocabs  = list(set(flatten(corpus_tokenized)))  #vocabs is a term defining all unique words your system know"
      ],
      "metadata": {
        "id": "LBD4zM3Wcvz0"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus2 = [\"river mountain nature\", \"mountain river nature\", \"mountain fountain river\",\n",
        "           \"fox rabbit animal\", \"rabbit fox animal\", \"rabbit animal fox\"]"
      ],
      "metadata": {
        "id": "zaKKwWPQc42V"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus2_tokenized = [sent.split(\" \") for sent in corpus2]\n",
        "corpus2_tokenized\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE-zriDpdeYC",
        "outputId": "9043b88f-24e6-449c-ef3b-8342ce130468"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['river', 'mountain', 'nature'],\n",
              " ['mountain', 'river', 'nature'],\n",
              " ['mountain', 'fountain', 'river'],\n",
              " ['fox', 'rabbit', 'animal'],\n",
              " ['rabbit', 'fox', 'animal'],\n",
              " ['rabbit', 'animal', 'fox']]"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try 2. numericalize\n",
        "#2.1 get all the unique words\n",
        "#we want to flatten this (basically merge all list)\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "vocabs2  = list(set(flatten(corpus2_tokenized)))  #vocabs is a term defining all unique words your system know"
      ],
      "metadata": {
        "id": "ly0hSbCQd4Ks"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2.2 assign id to all these vocabs\n",
        "word2index = {v: idx for idx, v in enumerate(vocabs)}"
      ],
      "metadata": {
        "id": "tu3LLlvJfajH"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4-ro_wkfgeM",
        "outputId": "8088c07c-20e5-456d-e9cc-2cde187e48d8"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dog': 0, 'animal': 1, 'apple': 2, 'fruit': 3, 'banana': 4, 'cat': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2index['apple']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVMvClzsfxvn",
        "outputId": "faa8e356-0925-47cc-dfa4-a8eeec4bd61f"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2index2 = {v: idx for idx, v in enumerate(vocabs2)}"
      ],
      "metadata": {
        "id": "p79Yp9nBf74W"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2index2['nature']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-duyHOUIf90y",
        "outputId": "309ce1b7-f2a7-4579-9fba-4d74c6f2564f"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#add <UNK>, which is a very normal token exists in the world\n",
        "vocabs.append('<UNK>') #chaky, can it be ##UNK, or UNKKKKKK, or anything"
      ],
      "metadata": {
        "id": "JJjUD8q5gGpw"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabs2.append('<UNK>')"
      ],
      "metadata": {
        "id": "LVove_Bdhanc"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now we have a way to know what is the id of <UNK>\n",
        "word2index['<UNK>'] = 6  #usually <UNK> is 0"
      ],
      "metadata": {
        "id": "wLVEbPEXheq7"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2index2['<UNK>'] = 7"
      ],
      "metadata": {
        "id": "jpyhi4zqhnGP"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create index2word dictionary\n",
        "#2 min    \n",
        "index2word = {v:k for k, v in word2index.items()}\n",
        "\n",
        "index2word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCXQLyT6hqZ7",
        "outputId": "debf5833-f9a6-4863-a565-cd1e40c5c8c3"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'dog',\n",
              " 1: 'animal',\n",
              " 2: 'apple',\n",
              " 3: 'fruit',\n",
              " 4: 'banana',\n",
              " 5: 'cat',\n",
              " 6: '<UNK>'}"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index2word2 = {v:k for k, v in word2index2.items()}\n",
        "index2word2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG31t3j1h4kj",
        "outputId": "513e802d-623a-4b43-9029-bb3029e1f146"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'fountain',\n",
              " 1: 'mountain',\n",
              " 2: 'animal',\n",
              " 3: 'nature',\n",
              " 4: 'fox',\n",
              " 5: 'rabbit',\n",
              " 6: 'river',\n",
              " 7: '<UNK>'}"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0_H5hSaiD9E",
        "outputId": "eb4210f4-b202-4d62-8701-6e915bc764f6"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dog', 'animal', 'apple', 'fruit', 'banana', 'cat', '<UNK>']"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabs2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMbLpyYxifwy",
        "outputId": "642a6aa8-236a-4960-8911-bbc08424b781"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fountain', 'mountain', 'animal', 'nature', 'fox', 'rabbit', 'river', '<UNK>']"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Prepare train data"
      ],
      "metadata": {
        "id": "NrV13joMioCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#move along the corpus\n",
        "#to fit with our corpus, we gonna use window_size = 1\n",
        "\n",
        "skipgrams = []\n",
        "\n",
        "#for each corpus\n",
        "for sent in corpus_tokenized:\n",
        "    #for each sent [\"apple\", \"banana\", \"fruit\"]\n",
        "    for i in range(1, len(sent) - 1): #start from 1 to second last\n",
        "        center_word = sent[i]\n",
        "        outside_words = [sent[i-1], sent[i+1]]  #window_size = 1\n",
        "        for o in outside_words:\n",
        "            skipgrams.append([center_word, o])\n",
        "\n",
        "skipgrams\n",
        "        \n",
        "#here we want to create (banana, apple), (banana, fruit) append to some list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plROA9D0ih-k",
        "outputId": "907c7ae6-fafa-442f-825a-b4a9aed89cef"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['banana', 'apple'],\n",
              " ['banana', 'fruit'],\n",
              " ['apple', 'banana'],\n",
              " ['apple', 'fruit'],\n",
              " ['fruit', 'banana'],\n",
              " ['fruit', 'apple'],\n",
              " ['cat', 'dog'],\n",
              " ['cat', 'animal'],\n",
              " ['dog', 'cat'],\n",
              " ['dog', 'animal'],\n",
              " ['animal', 'cat'],\n",
              " ['animal', 'dog']]"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #move along the corpus\n",
        "# #to fit with our corpus, we gonna use window_size = 1\n",
        "\n",
        "# skipgrams = []\n",
        "\n",
        "# #for each corpus\n",
        "# for sent in corpus2_tokenized:\n",
        "#     #for each sent [\"apple\", \"banana\", \"fruit\"]\n",
        "#     for i in range(1, len(sent) - 1): #start from 1 to second last\n",
        "#         center_word = sent[i]\n",
        "#         outside_words = [sent[i-1], sent[i+1]]  #window_size = 1\n",
        "#         for o in outside_words:\n",
        "#             skipgrams.append([center_word, o])\n",
        "\n",
        "# skipgrams\n",
        "        \n",
        "# #here we want to create (banana, apple), (banana, fruit) append to some list"
      ],
      "metadata": {
        "id": "AjWSOULNiwzo"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's make what we have made into a function (batch function)\n",
        "#return a batches of data, e.g., =2 --> ['banana', 'apple'], ['banana', 'fruit']\n",
        "#also i want these batches to be id, NOT token   --> [5, 4]\n",
        "\n",
        "def random_batch(batch_size, corpus):\n",
        "    \n",
        "    skipgrams = []\n",
        "\n",
        "    #for each corpus\n",
        "    for sent in corpus_tokenized:\n",
        "        #for each sent [\"apple\", \"banana\", \"fruit\"]\n",
        "        for i in range(1, len(sent) - 1): #start from 1 to second last\n",
        "            center_word = word2index[sent[i]]\n",
        "            outside_words = [word2index[sent[i-1]], word2index[sent[i+1]]]  #window_size = 1\n",
        "            for o in outside_words:\n",
        "                skipgrams.append([center_word, o])\n",
        "                \n",
        "    #only get a batch, not the entire list\n",
        "    random_index = np.random.choice(range(len(skipgrams)), batch_size, replace=False)\n",
        "             \n",
        "    #appending some list of inputs and labels\n",
        "    random_inputs, random_labels = [], []   \n",
        "    for index in random_index:\n",
        "        random_inputs.append([skipgrams[index][0]])  #center words, this will be a shape of (1, ) --> (1, 1) for modeling\n",
        "        random_labels.append([skipgrams[index][1]])\n",
        "        \n",
        "    return np.array(random_inputs), np.array(random_labels)\n",
        "    "
      ],
      "metadata": {
        "id": "-d_zclr_i3N8"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# def random_batch(batch_size,corpus):\n",
        "\n",
        "#   skipgram = []\n",
        "\n",
        "#   #for each corpus\n",
        "\n",
        "#   for sent in corpus2_tokenized:\n",
        "#         #for each sent [\"apple\", \"banana\", \"fruit\"]\n",
        "#         for i in range(1, len(sent) - 1): #start from 1 to second last\n",
        "#             center_word = word2index2[sent[i]]\n",
        "#             outside_words = [word2index2[sent[i-1]], word2index2[sent[i+1]]]  #window_size = 1\n",
        "#             for o in outside_words:\n",
        "#                 skipgrams.append([center_word, o])\n",
        "                \n",
        "#     #only get a batch, not the entire list\n",
        "    \n",
        "#   random_index = np.random.choice(range(len(skipgrams)), batch_size, replace=False)\n",
        "             \n",
        "#     #appending some list of inputs and labels\n",
        "\n",
        "#   random_inputs, random_labels = [], []   \n",
        "  \n",
        "#   for index in random_index:\n",
        "#         random_inputs.append([skipgrams[index][0]])  #center words, this will be a shape of (1, ) --> (1, 1) for modeling\n",
        "#         random_labels.append([skipgrams[index][1]])\n",
        "#   return np.array(random_inputs), np.array(random_labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "_KY_bVxhNILd"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input, label = random_batch(10, corpus_tokenized)\n",
        "\n",
        "print(f\"{input.shape}\")\n",
        "print(f\"{label=}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR2mxiu3Nm3V",
        "outputId": "12d323f9-4217-425d-9e47-e22e2bc72aaf"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 1)\n",
            "label=array([[4],\n",
            "       [5],\n",
            "       [2],\n",
            "       [1],\n",
            "       [1],\n",
            "       [3],\n",
            "       [4],\n",
            "       [0],\n",
            "       [3],\n",
            "       [5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # try starting from 2\n",
        "# def random_batch(batch_size,corpus):\n",
        "\n",
        "#   skipgram = []\n",
        "\n",
        "#   #for each corpus\n",
        "\n",
        "#   for sent in corpus2_tokenized:\n",
        "#         #for each sent [\"apple\", \"banana\", \"fruit\"]\n",
        "#         for i in range(2, len(sent) - 2): #start from 1 to second last\n",
        "#             center_word = word2index2[sent[i]]\n",
        "#             outside_words = [word2index2[sent[i-2]], word2index2[sent[i+2]]]  #window_size = 1\n",
        "#             for o in outside_words:\n",
        "#                 skipgrams.append([center_word, o])\n",
        "                \n",
        "#     #only get a batch, not the entire list\n",
        "    \n",
        "#   random_index = np.random.choice(range(len(skipgrams)), batch_size, replace=False)\n",
        "             \n",
        "#     #appending some list of inputs and labels\n",
        "\n",
        "#   random_inputs, random_labels = [], []   \n",
        "  \n",
        "#   for index in random_index:\n",
        "#         random_inputs.append([skipgrams[index][0]])  #center words, this will be a shape of (1, ) --> (1, 1) for modeling\n",
        "#         random_labels.append([skipgrams[index][1]])\n",
        "#   return np.array(random_inputs), np.array(random_labels)"
      ],
      "metadata": {
        "id": "umO3t7TUPnHo"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input, label = random_batch(10, corpus_tokenized)\n",
        "\n",
        "print(f\"{input.shape}\")\n",
        "print(f\"{label=}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmUbfUiYQXYd",
        "outputId": "d4cf0259-dd7a-45d6-bd09-3267ce722c33"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 1)\n",
            "label=array([[0],\n",
            "       [4],\n",
            "       [1],\n",
            "       [1],\n",
            "       [3],\n",
            "       [5],\n",
            "       [0],\n",
            "       [2],\n",
            "       [5],\n",
            "       [3]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Model"
      ],
      "metadata": {
        "id": "gRNy-yAvQnQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "voc_size = len(vocabs)\n",
        "voc_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDyLm04iQcQD",
        "outputId": "6d8ee4c1-3b43-4c71-e317-c2342dbca8f2"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "voc_size2 = len(vocabs2)\n",
        "voc_size2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az-ubU_yQqoZ",
        "outputId": "96c2755e-23e8-4141-8bf9-5e3237007be8"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the model will accept three vectors - u_o, v_c, u_w\n",
        "#u_o - vector for outside words\n",
        "#v_c - vector for center word\n",
        "#u_w - vectors of all vocabs\n",
        "\n",
        "class Skipgram(nn.Module):\n",
        "    \n",
        "    def __init__(self, voc_size, emb_size):\n",
        "        super(Skipgram, self).__init__()\n",
        "        self.embedding_center_word  = nn.Embedding(voc_size, emb_size)  #is a lookup table mapping all ids in voc_size, into some vector of size emb_size\n",
        "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
        "    \n",
        "    def forward(self, center_word, outside_word, all_vocabs):\n",
        "        #center_word, outside_word: (batch_size, 1)\n",
        "        #all_vocabs: (batch_size, voc_size)\n",
        "        \n",
        "        #convert them into embedding\n",
        "        center_word_embed  = self.embedding_center_word(center_word)     #(batch_size, 1, emb_size)\n",
        "        outside_word_embed = self.embedding_outside_word(outside_word)   #(batch_size, 1, emb_size)\n",
        "        all_vocabs_embed   = self.embedding_outside_word(all_vocabs)     #(batch_size, voc_size, emb_size)\n",
        "        \n",
        "        #bmm is basically @ or .dot , but across batches (i.e., ignore the batch dimension)\n",
        "        top_term = outside_word_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
        "        #(batch_size, 1, emb_size) @ (batch_size, emb_size, 1) = (batch_size, 1, 1) ===> (batch_size, 1)\n",
        "        \n",
        "        top_term_exp = torch.exp(top_term)  #exp(uo vc)\n",
        "        #(batch_size, 1)\n",
        "        \n",
        "        lower_term = all_vocabs_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
        "         #(batch_size, voc_size, emb_size) @ (batch_size, emb_size, 1) = (batch_size, voc_size, 1) = (batch_size, voc_size)\n",
        "         \n",
        "        lower_term_sum = torch.sum(torch.exp(lower_term), 1) #sum exp(uw vc)\n",
        "        #(batch_size, 1)\n",
        "        \n",
        "        loss_fn = -torch.mean(torch.log(top_term_exp / lower_term_sum))\n",
        "        #(batch_size, 1) / (batch_size, 1) ==mean==> scalar\n",
        "        \n",
        "        return loss_fn"
      ],
      "metadata": {
        "id": "8d49AxSQQwa8"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preparing all_vocabs\n",
        "\n",
        "batch_size = 2\n",
        "\n",
        "def prepare_sequence(seq, word2index):\n",
        "    #map(function, list of something)\n",
        "    #map will look at each of element in this list, and apply this function\n",
        "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
        "    return torch.LongTensor(idxs)\n",
        "\n",
        "all_vocabs = prepare_sequence(list(vocabs), word2index).expand(batch_size, voc_size)\n",
        "all_vocabs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzTuq8t8RkyS",
        "outputId": "345a62a3-0644-4e97-8721-acdff58afba0"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "voc_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDqvrUHKS37I",
        "outputId": "bdecc6af-7a74-4e65-b616-698adda62143"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "voc_size2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96RkPo-ZUDiU",
        "outputId": "6f830dc6-b1fc-4fc2-a44e-7d35f21c7736"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input, label = random_batch(batch_size, corpus_tokenized)\n",
        "input #center word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6msA2jmTgTQ",
        "outputId": "408b1e69-4339-4ef2-8da0-ae8cc228ab6c"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5],\n",
              "       [3]])"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiYThkEsUgcl",
        "outputId": "3162b53a-302f-4316-eb75-f9db56fec0d1"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [2]])"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input2, label2 = random_batch(batch_size, corpus2_tokenized)\n",
        "input2 #center word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfM8gx6RThS0",
        "outputId": "252038e6-b292-44ee-b0ad-d1499aa6a7b0"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REPFOj9ZT-RM",
        "outputId": "dfd14de6-4981-4e58-d89e-a986f235a304"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3],\n",
              "       [5]])"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "voc_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvMLKMwPUayC",
        "outputId": "c80a434e-f414-4d30-99c7-5047f0430981"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "voc_size2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlFPonpgVATW",
        "outputId": "4900e982-e68f-40ee-b605-190d5fb8d2c9"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb_size = 2 #usually, this can be 50, 100, or 300\n",
        "model = Skipgram(voc_size, emb_size)"
      ],
      "metadata": {
        "id": "8pUehlfzVCMV"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = torch.LongTensor(input)  \n",
        "label_tensor = torch.LongTensor(label)  #LongTensor basically means integer...."
      ],
      "metadata": {
        "id": "LL4u6D29VWbC"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this is different\n",
        "torch.LongTensor(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN5rgqaAVZIu",
        "outputId": "56038c63-516d-4766-fbad-a132146dbc24"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3199092244751596066, 7304682900672553504])"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.LongTensor([2])  #put shape (, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezGRuQd9VdAO",
        "outputId": "e5f6c161-a05e-4a27-df66-968c5680212c"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2])"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UhquCqxVkyz",
        "outputId": "ebd62e27-923f-4db5-97b1-aac26a499da3"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYBq4lfJVwAS",
        "outputId": "aaced7a2-d720-42f8-b167-cb2a155e7120"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_vocabs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZuQJie1V2Xr",
        "outputId": "ecb813be-2ed2-4d0b-f627-2d22141eb7df"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2, 3, 4, 5, 6],\n",
              "        [0, 1, 2, 3, 4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this should give one number\n",
        "loss = model(input_tensor, label_tensor, all_vocabs)"
      ],
      "metadata": {
        "id": "oacNQQOaV-Uy"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Training"
      ],
      "metadata": {
        "id": "q7OahtBiZRvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2 #why?  no reason; \n",
        "emb_size   = 2 #why?  no reason; usually 50, 100, 300, but 2 so we can plot (50 can also plot, but need PCA)\n",
        "model      = Skipgram(voc_size, emb_size)\n",
        "\n",
        "optimizer  = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "ETBBDiFTWFEJ"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5000\n",
        "#for epoch\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    #get random batch\n",
        "    input_batch, label_batch = random_batch(batch_size, corpus)\n",
        "    input_batch = torch.LongTensor(input_batch)\n",
        "    label_batch = torch.LongTensor(label_batch)\n",
        "    \n",
        "    # print(input_batch.shape, label_batch.shape, all_vocabs.shape)\n",
        "    \n",
        "    #loss = model\n",
        "    \n",
        "    loss = model(input_batch, label_batch, all_vocabs)\n",
        "    \n",
        "    #backpropagate\n",
        "    loss.backward()\n",
        "    \n",
        "    #update alpha\n",
        "    optimizer.step()\n",
        "    \n",
        "    #print epoch loss\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print(f\"Epoch {epoch+1} | Loss: {loss:.6f} | Time: ??\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2I23g1uzZYej",
        "outputId": "50ebb11a-c84a-4a4b-8230-2e35790f9646"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1000 | Loss: 0.820913 | Time: ??\n",
            "Epoch 2000 | Loss: 1.048916 | Time: ??\n",
            "Epoch 3000 | Loss: 0.801917 | Time: ??\n",
            "Epoch 4000 | Loss: 1.000895 | Time: ??\n",
            "Epoch 5000 | Loss: 1.616409 | Time: ??\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Plot the embeddings"
      ],
      "metadata": {
        "id": "CAusn-U_ePyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvUi-ZoSZcr7",
        "outputId": "557b6c23-e45f-48e4-cdb2-fbc85b12fa80"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dog', 'animal', 'apple', 'fruit', 'banana', 'cat', '<UNK>']"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "banana = torch.LongTensor([word2index['banana']])\n",
        "banana"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XyrTVideVgO",
        "outputId": "55b69ebc-740b-42a6-ebdb-8407117998cf"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4])"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "banana_center_embed = model.embedding_center_word(banana)\n",
        "banana_outisde_embed = model.embedding_outside_word(banana)\n",
        "\n",
        "banana_embed = (banana_center_embed + banana_outisde_embed) / 2\n",
        "banana_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ekb2Es2feXrR",
        "outputId": "a6a62498-d003-417e-e7b7-4899b3ffae57"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4.0533, 2.1779]], grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embed(word):\n",
        "    try:\n",
        "        index = word2index[word]\n",
        "    except:\n",
        "        index = word2index['<UNK>']\n",
        "    \n",
        "    word = torch.LongTensor([index])\n",
        "\n",
        "    center_embed  = model.embedding_center_word(word)\n",
        "    outside_embed = model.embedding_outside_word(word)\n",
        "    \n",
        "    embed = (center_embed + outside_embed) / 2\n",
        "    \n",
        "    return  embed[0][0].item(), embed[0][1].item()"
      ],
      "metadata": {
        "id": "hV2tAJZzef-N"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#find embedding of fruit, cat\n",
        "print(get_embed('fruit'))\n",
        "print(get_embed('cat'))\n",
        "\n",
        "print(get_embed('chaky'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaTn-_x-elW4",
        "outputId": "8123eeb0-f2d7-4e91-b4bb-889c51c44c1c"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3.3184046745300293, 4.636585235595703)\n",
            "(-3.149721622467041, -3.2000458240509033)\n",
            "(-0.28349125385284424, 0.5217384696006775)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#help me plot fruit cat banana on matplotlib\n",
        "plt.figure(figsize=(6,3))\n",
        "for i, word in enumerate(vocabs[:20]): #loop each unique vocab\n",
        "    x, y = get_embed(word)\n",
        "    plt.scatter(x, y)\n",
        "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "_CNyaulLeraV",
        "outputId": "8fc3d4b9-e84f-4398-f550-6a385083d03e"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bfYyrI-Te4nP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}