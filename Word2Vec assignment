{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e702c219-ac86-4342-99ea-3dd26ca5491e",
   "metadata": {},
   "source": [
    "## Word2Vec Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278f285a-a07c-45f6-89ca-fe6e9ae2fa6e",
   "metadata": {},
   "source": [
    "You MUST build on top of what we have coded in the class (to prevent anyone from just copying from the internet).\n",
    "\n",
    "1.  Try a real corpus (instead of banana apple, try something real... on the internet....) - not so big!  Just so you have a good taste of real stuff....like 50 documents, each having 50 words...(really up to you)\n",
    "\n",
    "2. Try a window size of 2\n",
    "\n",
    "3. Implement CBOW (instead of skipgrams)\n",
    "\n",
    "4. Compare normal version of skipgrams vs. negative sampling version of skipgrams in terms of time (using real corpus)\n",
    "\n",
    "Point criteria:\n",
    "0: not done/copy directly from your friend (inspired is ok)\n",
    "1: ok\n",
    "2: with comments, and a nice explanation along the notebook (like how Chaky do his tutorial...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3508cb9-3977-4c50-ac14-d4e2ade8455b",
   "metadata": {},
   "source": [
    "Name: Podchanan Rungthirakul\n",
    "\n",
    "StudentID: st123460"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "371279fa-0ccd-498e-bd6a-21e1ace9b58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c13fea6-0204-45aa-bba3-57438192a959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c01d6b84-9229-4d94-a5ee-59b3967afa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e9b67a-747d-4952-bf99-5d5962cf6932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "581f5ffe-87d9-4f41-ae81-1b16520f28ea",
   "metadata": {},
   "source": [
    "## 1. Load the data\n",
    "\n",
    "I use my interested informations about jazz music as a corpus for the data in here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c87cbde2-194d-4a12-9810-30d6aa1ce746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.2'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79b60eef-e108-4e8a-a2b4-0b52c5e4d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f919282-ff96-47e5-aed3-f758e283d3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the informations of jazz music from Wikipedia in corpus\n",
    "corpus = [\"Jazz is a music genre that originated in the African-American communities of New Orleans, Louisiana, in the late 19th and early 20th centuries, with its roots in blues and ragtime.[1][2][3][4] Since the 1920s Jazz Age, it has been recognized as a major form of musical expression in traditional and popular music. Jazz is characterized by swing and blue notes, complex chords, call and response vocals, polyrhythms and improvisation. Jazz has roots in European harmony and African rhythmic rituals.\",\n",
    "         \"As jazz spread around the world, it drew on national, regional, and local musical cultures, which gave rise to different styles. New Orleans jazz began in the early 1910s, combining earlier brass band marches, French quadrilles, biguine, ragtime and blues with collective polyphonic improvisation. But jazz did not begin as a single musical tradition in New Orleans or elsewhere. In the 1930s, arranged dance-oriented swing big bands, Kansas City jazz (a hard-swinging, bluesy, improvisational style), and gypsy jazz (a style that emphasized musette waltzes) were the prominent styles. Bebop emerged in the 1940s, shifting jazz from danceable popular music toward a more challenging 'musician's music' which was played at faster tempos and used more chord-based improvisation. Cool jazz developed near the end of the 1940s, introducing calmer, smoother sounds and long, linear melodic lines.\",\n",
    "         \"The mid-1950s saw the emergence of hard bop, which introduced influences from rhythm and blues, gospel, and blues to small groups and particularly to saxophone and piano. Modal jazz developed in the late 1950s, using the mode, or musical scale, as the basis of musical structure and improvisation, as did free jazz, which explored playing without regular meter, beat and formal structures. Jazz-rock fusion appeared in the late 1960s and early 1970s, combining jazz improvisation with rock music's rhythms, electric instruments, and highly amplified stage sound. In the early 1980s, a commercial form of jazz fusion called smooth jazz became successful, garnering significant radio airplay. Other styles and genres abound in the 21st century, such as Latin and Afro-Cuban jazz.\",\n",
    "         \"The origin of the word jazz has resulted in considerable research, and its history is well documented. It is believed to be related to jasm, a slang term dating back to 1860 meaning 'pep, energy'. The earliest written record of the word is in a 1912 article in the Los Angeles Times in which a minor league baseball pitcher described a pitch which he called a 'jazz ball' because it wobbles and you simply can't do anything with it.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bd3c731-f43f-4a77-b74c-9a4f2425447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tokenized = []\n",
    "for i in range(len(corpus)):\n",
    "    corpus_tokenized.append([str(token) for token in nlp([c for c in corpus][i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "744ba48e-bf48-4d1e-ba65-c3f46883c4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Jazz',\n",
       "  'is',\n",
       "  'a',\n",
       "  'music',\n",
       "  'genre',\n",
       "  'that',\n",
       "  'originated',\n",
       "  'in',\n",
       "  'the',\n",
       "  'African',\n",
       "  '-',\n",
       "  'American',\n",
       "  'communities',\n",
       "  'of',\n",
       "  'New',\n",
       "  'Orleans',\n",
       "  ',',\n",
       "  'Louisiana',\n",
       "  ',',\n",
       "  'in',\n",
       "  'the',\n",
       "  'late',\n",
       "  '19th',\n",
       "  'and',\n",
       "  'early',\n",
       "  '20th',\n",
       "  'centuries',\n",
       "  ',',\n",
       "  'with',\n",
       "  'its',\n",
       "  'roots',\n",
       "  'in',\n",
       "  'blues',\n",
       "  'and',\n",
       "  'ragtime.[1][2][3][4',\n",
       "  ']',\n",
       "  'Since',\n",
       "  'the',\n",
       "  '1920s',\n",
       "  'Jazz',\n",
       "  'Age',\n",
       "  ',',\n",
       "  'it',\n",
       "  'has',\n",
       "  'been',\n",
       "  'recognized',\n",
       "  'as',\n",
       "  'a',\n",
       "  'major',\n",
       "  'form',\n",
       "  'of',\n",
       "  'musical',\n",
       "  'expression',\n",
       "  'in',\n",
       "  'traditional',\n",
       "  'and',\n",
       "  'popular',\n",
       "  'music',\n",
       "  '.',\n",
       "  'Jazz',\n",
       "  'is',\n",
       "  'characterized',\n",
       "  'by',\n",
       "  'swing',\n",
       "  'and',\n",
       "  'blue',\n",
       "  'notes',\n",
       "  ',',\n",
       "  'complex',\n",
       "  'chords',\n",
       "  ',',\n",
       "  'call',\n",
       "  'and',\n",
       "  'response',\n",
       "  'vocals',\n",
       "  ',',\n",
       "  'polyrhythms',\n",
       "  'and',\n",
       "  'improvisation',\n",
       "  '.',\n",
       "  'Jazz',\n",
       "  'has',\n",
       "  'roots',\n",
       "  'in',\n",
       "  'European',\n",
       "  'harmony',\n",
       "  'and',\n",
       "  'African',\n",
       "  'rhythmic',\n",
       "  'rituals',\n",
       "  '.'],\n",
       " ['As',\n",
       "  'jazz',\n",
       "  'spread',\n",
       "  'around',\n",
       "  'the',\n",
       "  'world',\n",
       "  ',',\n",
       "  'it',\n",
       "  'drew',\n",
       "  'on',\n",
       "  'national',\n",
       "  ',',\n",
       "  'regional',\n",
       "  ',',\n",
       "  'and',\n",
       "  'local',\n",
       "  'musical',\n",
       "  'cultures',\n",
       "  ',',\n",
       "  'which',\n",
       "  'gave',\n",
       "  'rise',\n",
       "  'to',\n",
       "  'different',\n",
       "  'styles',\n",
       "  '.',\n",
       "  'New',\n",
       "  'Orleans',\n",
       "  'jazz',\n",
       "  'began',\n",
       "  'in',\n",
       "  'the',\n",
       "  'early',\n",
       "  '1910s',\n",
       "  ',',\n",
       "  'combining',\n",
       "  'earlier',\n",
       "  'brass',\n",
       "  'band',\n",
       "  'marches',\n",
       "  ',',\n",
       "  'French',\n",
       "  'quadrilles',\n",
       "  ',',\n",
       "  'biguine',\n",
       "  ',',\n",
       "  'ragtime',\n",
       "  'and',\n",
       "  'blues',\n",
       "  'with',\n",
       "  'collective',\n",
       "  'polyphonic',\n",
       "  'improvisation',\n",
       "  '.',\n",
       "  'But',\n",
       "  'jazz',\n",
       "  'did',\n",
       "  'not',\n",
       "  'begin',\n",
       "  'as',\n",
       "  'a',\n",
       "  'single',\n",
       "  'musical',\n",
       "  'tradition',\n",
       "  'in',\n",
       "  'New',\n",
       "  'Orleans',\n",
       "  'or',\n",
       "  'elsewhere',\n",
       "  '.',\n",
       "  'In',\n",
       "  'the',\n",
       "  '1930s',\n",
       "  ',',\n",
       "  'arranged',\n",
       "  'dance',\n",
       "  '-',\n",
       "  'oriented',\n",
       "  'swing',\n",
       "  'big',\n",
       "  'bands',\n",
       "  ',',\n",
       "  'Kansas',\n",
       "  'City',\n",
       "  'jazz',\n",
       "  '(',\n",
       "  'a',\n",
       "  'hard',\n",
       "  '-',\n",
       "  'swinging',\n",
       "  ',',\n",
       "  'bluesy',\n",
       "  ',',\n",
       "  'improvisational',\n",
       "  'style',\n",
       "  ')',\n",
       "  ',',\n",
       "  'and',\n",
       "  'gypsy',\n",
       "  'jazz',\n",
       "  '(',\n",
       "  'a',\n",
       "  'style',\n",
       "  'that',\n",
       "  'emphasized',\n",
       "  'musette',\n",
       "  'waltzes',\n",
       "  ')',\n",
       "  'were',\n",
       "  'the',\n",
       "  'prominent',\n",
       "  'styles',\n",
       "  '.',\n",
       "  'Bebop',\n",
       "  'emerged',\n",
       "  'in',\n",
       "  'the',\n",
       "  '1940s',\n",
       "  ',',\n",
       "  'shifting',\n",
       "  'jazz',\n",
       "  'from',\n",
       "  'danceable',\n",
       "  'popular',\n",
       "  'music',\n",
       "  'toward',\n",
       "  'a',\n",
       "  'more',\n",
       "  'challenging',\n",
       "  \"'\",\n",
       "  'musician',\n",
       "  \"'s\",\n",
       "  'music',\n",
       "  \"'\",\n",
       "  'which',\n",
       "  'was',\n",
       "  'played',\n",
       "  'at',\n",
       "  'faster',\n",
       "  'tempos',\n",
       "  'and',\n",
       "  'used',\n",
       "  'more',\n",
       "  'chord',\n",
       "  '-',\n",
       "  'based',\n",
       "  'improvisation',\n",
       "  '.',\n",
       "  'Cool',\n",
       "  'jazz',\n",
       "  'developed',\n",
       "  'near',\n",
       "  'the',\n",
       "  'end',\n",
       "  'of',\n",
       "  'the',\n",
       "  '1940s',\n",
       "  ',',\n",
       "  'introducing',\n",
       "  'calmer',\n",
       "  ',',\n",
       "  'smoother',\n",
       "  'sounds',\n",
       "  'and',\n",
       "  'long',\n",
       "  ',',\n",
       "  'linear',\n",
       "  'melodic',\n",
       "  'lines',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'mid-1950s',\n",
       "  'saw',\n",
       "  'the',\n",
       "  'emergence',\n",
       "  'of',\n",
       "  'hard',\n",
       "  'bop',\n",
       "  ',',\n",
       "  'which',\n",
       "  'introduced',\n",
       "  'influences',\n",
       "  'from',\n",
       "  'rhythm',\n",
       "  'and',\n",
       "  'blues',\n",
       "  ',',\n",
       "  'gospel',\n",
       "  ',',\n",
       "  'and',\n",
       "  'blues',\n",
       "  'to',\n",
       "  'small',\n",
       "  'groups',\n",
       "  'and',\n",
       "  'particularly',\n",
       "  'to',\n",
       "  'saxophone',\n",
       "  'and',\n",
       "  'piano',\n",
       "  '.',\n",
       "  'Modal',\n",
       "  'jazz',\n",
       "  'developed',\n",
       "  'in',\n",
       "  'the',\n",
       "  'late',\n",
       "  '1950s',\n",
       "  ',',\n",
       "  'using',\n",
       "  'the',\n",
       "  'mode',\n",
       "  ',',\n",
       "  'or',\n",
       "  'musical',\n",
       "  'scale',\n",
       "  ',',\n",
       "  'as',\n",
       "  'the',\n",
       "  'basis',\n",
       "  'of',\n",
       "  'musical',\n",
       "  'structure',\n",
       "  'and',\n",
       "  'improvisation',\n",
       "  ',',\n",
       "  'as',\n",
       "  'did',\n",
       "  'free',\n",
       "  'jazz',\n",
       "  ',',\n",
       "  'which',\n",
       "  'explored',\n",
       "  'playing',\n",
       "  'without',\n",
       "  'regular',\n",
       "  'meter',\n",
       "  ',',\n",
       "  'beat',\n",
       "  'and',\n",
       "  'formal',\n",
       "  'structures',\n",
       "  '.',\n",
       "  'Jazz',\n",
       "  '-',\n",
       "  'rock',\n",
       "  'fusion',\n",
       "  'appeared',\n",
       "  'in',\n",
       "  'the',\n",
       "  'late',\n",
       "  '1960s',\n",
       "  'and',\n",
       "  'early',\n",
       "  '1970s',\n",
       "  ',',\n",
       "  'combining',\n",
       "  'jazz',\n",
       "  'improvisation',\n",
       "  'with',\n",
       "  'rock',\n",
       "  'music',\n",
       "  \"'s\",\n",
       "  'rhythms',\n",
       "  ',',\n",
       "  'electric',\n",
       "  'instruments',\n",
       "  ',',\n",
       "  'and',\n",
       "  'highly',\n",
       "  'amplified',\n",
       "  'stage',\n",
       "  'sound',\n",
       "  '.',\n",
       "  'In',\n",
       "  'the',\n",
       "  'early',\n",
       "  '1980s',\n",
       "  ',',\n",
       "  'a',\n",
       "  'commercial',\n",
       "  'form',\n",
       "  'of',\n",
       "  'jazz',\n",
       "  'fusion',\n",
       "  'called',\n",
       "  'smooth',\n",
       "  'jazz',\n",
       "  'became',\n",
       "  'successful',\n",
       "  ',',\n",
       "  'garnering',\n",
       "  'significant',\n",
       "  'radio',\n",
       "  'airplay',\n",
       "  '.',\n",
       "  'Other',\n",
       "  'styles',\n",
       "  'and',\n",
       "  'genres',\n",
       "  'abound',\n",
       "  'in',\n",
       "  'the',\n",
       "  '21st',\n",
       "  'century',\n",
       "  ',',\n",
       "  'such',\n",
       "  'as',\n",
       "  'Latin',\n",
       "  'and',\n",
       "  'Afro',\n",
       "  '-',\n",
       "  'Cuban',\n",
       "  'jazz',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'origin',\n",
       "  'of',\n",
       "  'the',\n",
       "  'word',\n",
       "  'jazz',\n",
       "  'has',\n",
       "  'resulted',\n",
       "  'in',\n",
       "  'considerable',\n",
       "  'research',\n",
       "  ',',\n",
       "  'and',\n",
       "  'its',\n",
       "  'history',\n",
       "  'is',\n",
       "  'well',\n",
       "  'documented',\n",
       "  '.',\n",
       "  'It',\n",
       "  'is',\n",
       "  'believed',\n",
       "  'to',\n",
       "  'be',\n",
       "  'related',\n",
       "  'to',\n",
       "  'jasm',\n",
       "  ',',\n",
       "  'a',\n",
       "  'slang',\n",
       "  'term',\n",
       "  'dating',\n",
       "  'back',\n",
       "  'to',\n",
       "  '1860',\n",
       "  'meaning',\n",
       "  \"'\",\n",
       "  'pep',\n",
       "  ',',\n",
       "  'energy',\n",
       "  \"'\",\n",
       "  '.',\n",
       "  'The',\n",
       "  'earliest',\n",
       "  'written',\n",
       "  'record',\n",
       "  'of',\n",
       "  'the',\n",
       "  'word',\n",
       "  'is',\n",
       "  'in',\n",
       "  'a',\n",
       "  '1912',\n",
       "  'article',\n",
       "  'in',\n",
       "  'the',\n",
       "  'Los',\n",
       "  'Angeles',\n",
       "  'Times',\n",
       "  'in',\n",
       "  'which',\n",
       "  'a',\n",
       "  'minor',\n",
       "  'league',\n",
       "  'baseball',\n",
       "  'pitcher',\n",
       "  'described',\n",
       "  'a',\n",
       "  'pitch',\n",
       "  'which',\n",
       "  'he',\n",
       "  'called',\n",
       "  'a',\n",
       "  \"'\",\n",
       "  'jazz',\n",
       "  'ball',\n",
       "  \"'\",\n",
       "  'because',\n",
       "  'it',\n",
       "  'wobbles',\n",
       "  'and',\n",
       "  'you',\n",
       "  'simply',\n",
       "  'ca',\n",
       "  \"n't\",\n",
       "  'do',\n",
       "  'anything',\n",
       "  'with',\n",
       "  'it',\n",
       "  '.']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a86bd5e-c8f4-4c27-84b3-20b21cb6b8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. numericalize\n",
    "\n",
    "#2.1 get all the unique words\n",
    "#we want to flatten this (basically merge all list)\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "vocabs  = list(set(flatten(corpus_tokenized)))  \n",
    "#vocabs is a term defining all unique words your system know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5306ecf8-bcd0-4055-8cac-4fac2a626bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2 assign id to all these vocabs\n",
    "word2index = {v: idx for idx, v in enumerate(vocabs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "169c625e-1203-4f9e-8d5b-dc5fc1a13f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index['jazz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7607f28-8b5e-4369-9761-5743a3250e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index['instruments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa3e40f1-32cf-4654-a26c-e56732b9eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add <UNK>, which is a very normal token exists in the world\n",
    "vocabs.append('<UNK>') #chaky, can it be ##UNK, or UNKKKKKK, or anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70e72d92-e51d-4cac-bcac-0db40fcd160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we have a way to know what is the id of <UNK>\n",
    "word2index['<UNK>'] = 0  #I set <UNK> as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45a35d57-1033-403b-a178-867b1c5e769a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<UNK>',\n",
       " 1: 'Jazz',\n",
       " 2: 'tradition',\n",
       " 3: 'biguine',\n",
       " 4: 'do',\n",
       " 5: 'big',\n",
       " 6: 'or',\n",
       " 7: 'Louisiana',\n",
       " 8: '1860',\n",
       " 9: 'rhythm',\n",
       " 10: '1910s',\n",
       " 11: 'league',\n",
       " 12: 'dance',\n",
       " 13: 'smooth',\n",
       " 14: 'quadrilles',\n",
       " 15: 'As',\n",
       " 16: 'late',\n",
       " 17: 'rituals',\n",
       " 18: 'pitch',\n",
       " 19: 'traditional',\n",
       " 20: 'free',\n",
       " 21: 'styles',\n",
       " 22: 'described',\n",
       " 23: 'cultures',\n",
       " 24: 'bluesy',\n",
       " 25: 'baseball',\n",
       " 26: 'lines',\n",
       " 27: 'harmony',\n",
       " 28: 'introducing',\n",
       " 29: 'pep',\n",
       " 30: 'highly',\n",
       " 31: 'different',\n",
       " 32: 'style',\n",
       " 33: 'musician',\n",
       " 34: 'as',\n",
       " 35: 'meter',\n",
       " 36: 'improvisation',\n",
       " 37: 'genre',\n",
       " 38: 'meaning',\n",
       " 39: 'French',\n",
       " 40: 'that',\n",
       " 41: 'complex',\n",
       " 42: 'chord',\n",
       " 43: 'end',\n",
       " 44: 'saw',\n",
       " 45: 'In',\n",
       " 46: 'without',\n",
       " 47: 'called',\n",
       " 48: 'dating',\n",
       " 49: 'played',\n",
       " 50: 'structure',\n",
       " 51: 'local',\n",
       " 52: 'piano',\n",
       " 53: 'instruments',\n",
       " 54: 'Cool',\n",
       " 55: 'small',\n",
       " 56: 'Other',\n",
       " 57: 'chords',\n",
       " 58: 'simply',\n",
       " 59: 'music',\n",
       " 60: 'musical',\n",
       " 61: 'swing',\n",
       " 62: 'rise',\n",
       " 63: 'Bebop',\n",
       " 64: 'electric',\n",
       " 65: 'elsewhere',\n",
       " 66: 'successful',\n",
       " 67: 'African',\n",
       " 68: 'faster',\n",
       " 69: 'recognized',\n",
       " 70: 'The',\n",
       " 71: 'appeared',\n",
       " 72: 'the',\n",
       " 73: 'emergence',\n",
       " 74: 'arranged',\n",
       " 75: '.',\n",
       " 76: 'sounds',\n",
       " 77: '1960s',\n",
       " 78: 'Angeles',\n",
       " 79: 'wobbles',\n",
       " 80: 'shifting',\n",
       " 81: 'tempos',\n",
       " 82: 'sound',\n",
       " 83: 'energy',\n",
       " 84: 'musette',\n",
       " 85: 'considerable',\n",
       " 86: 'on',\n",
       " 87: 'regional',\n",
       " 88: 'earliest',\n",
       " 89: ',',\n",
       " 90: 'Cuban',\n",
       " 91: 'minor',\n",
       " 92: 'toward',\n",
       " 93: 'stage',\n",
       " 94: 'because',\n",
       " 95: '(',\n",
       " 96: \"'s\",\n",
       " 97: 'ragtime.[1][2][3][4',\n",
       " 98: 'begin',\n",
       " 99: 'its',\n",
       " 100: 'be',\n",
       " 101: \"'\",\n",
       " 102: 'melodic',\n",
       " 103: '19th',\n",
       " 104: 'which',\n",
       " 105: 'fusion',\n",
       " 106: '1930s',\n",
       " 107: 'rhythms',\n",
       " 108: '21st',\n",
       " 109: 'Orleans',\n",
       " 110: 'national',\n",
       " 111: 'such',\n",
       " 112: 'term',\n",
       " 113: 'mode',\n",
       " 114: 'to',\n",
       " 115: 'combining',\n",
       " 116: 'Afro',\n",
       " 117: 'well',\n",
       " 118: 'research',\n",
       " 119: 'response',\n",
       " 120: 'marches',\n",
       " 121: 'believed',\n",
       " 122: '1950s',\n",
       " 123: 'major',\n",
       " 124: 'developed',\n",
       " 125: 'early',\n",
       " 126: 'he',\n",
       " 127: 'influences',\n",
       " 128: 'ca',\n",
       " 129: 'call',\n",
       " 130: 'collective',\n",
       " 131: 'swinging',\n",
       " 132: 'Latin',\n",
       " 133: 'Age',\n",
       " 134: 'world',\n",
       " 135: 'emphasized',\n",
       " 136: 'saxophone',\n",
       " 137: 'playing',\n",
       " 138: 'rock',\n",
       " 139: 'more',\n",
       " 140: 'amplified',\n",
       " 141: 'back',\n",
       " 142: 'centuries',\n",
       " 143: 'regular',\n",
       " 144: 'record',\n",
       " 145: 'spread',\n",
       " 146: 'particularly',\n",
       " 147: '1940s',\n",
       " 148: 'anything',\n",
       " 149: 'linear',\n",
       " 150: 'brass',\n",
       " 151: 'American',\n",
       " 152: 'City',\n",
       " 153: 'explored',\n",
       " 154: 'commercial',\n",
       " 155: 'significant',\n",
       " 156: 'began',\n",
       " 157: 'based',\n",
       " 158: 'Since',\n",
       " 159: 'formal',\n",
       " 160: 'gave',\n",
       " 161: 'bop',\n",
       " 162: '1970s',\n",
       " 163: 'characterized',\n",
       " 164: 'around',\n",
       " 165: 'drew',\n",
       " 166: 'long',\n",
       " 167: 'structures',\n",
       " 168: 'waltzes',\n",
       " 169: 'in',\n",
       " 170: 'jasm',\n",
       " 171: 'used',\n",
       " 172: 'earlier',\n",
       " 173: 'word',\n",
       " 174: 'roots',\n",
       " 175: 'gospel',\n",
       " 176: 'you',\n",
       " 177: 'using',\n",
       " 178: 'not',\n",
       " 179: 'basis',\n",
       " 180: 'at',\n",
       " 181: 'was',\n",
       " 182: 'polyrhythms',\n",
       " 183: '-',\n",
       " 184: 'danceable',\n",
       " 185: 'scale',\n",
       " 186: 'is',\n",
       " 187: 'been',\n",
       " 188: 'smoother',\n",
       " 189: ']',\n",
       " 190: 'improvisational',\n",
       " 191: 'written',\n",
       " 192: 'with',\n",
       " 193: 'and',\n",
       " 194: 'rhythmic',\n",
       " 195: '1920s',\n",
       " 196: 'prominent',\n",
       " 197: 'blue',\n",
       " 198: 'expression',\n",
       " 199: 'popular',\n",
       " 200: 'resulted',\n",
       " 201: 'slang',\n",
       " 202: 'documented',\n",
       " 203: 'hard',\n",
       " 204: 'jazz',\n",
       " 205: 'gypsy',\n",
       " 206: 'European',\n",
       " 207: 'groups',\n",
       " 208: 'ragtime',\n",
       " 209: 'century',\n",
       " 210: 'originated',\n",
       " 211: 'of',\n",
       " 212: 'history',\n",
       " 213: 'calmer',\n",
       " 214: ')',\n",
       " 215: 'became',\n",
       " 216: \"n't\",\n",
       " 217: 'blues',\n",
       " 218: 'mid-1950s',\n",
       " 219: 'introduced',\n",
       " 220: 'were',\n",
       " 221: 'article',\n",
       " 222: '20th',\n",
       " 223: 'It',\n",
       " 224: 'has',\n",
       " 225: 'by',\n",
       " 226: 'did',\n",
       " 227: 'radio',\n",
       " 228: 'Modal',\n",
       " 229: '1912',\n",
       " 230: 'Los',\n",
       " 231: 'a',\n",
       " 232: 'emerged',\n",
       " 233: 'challenging',\n",
       " 234: 'origin',\n",
       " 235: 'pitcher',\n",
       " 236: 'bands',\n",
       " 237: 'near',\n",
       " 238: 'garnering',\n",
       " 239: 'airplay',\n",
       " 240: 'New',\n",
       " 241: 'But',\n",
       " 242: 'Kansas',\n",
       " 243: 'genres',\n",
       " 244: 'form',\n",
       " 245: 'beat',\n",
       " 246: 'polyphonic',\n",
       " 247: 'band',\n",
       " 248: 'related',\n",
       " 249: 'Times',\n",
       " 250: 'ball',\n",
       " 251: 'oriented',\n",
       " 252: 'single',\n",
       " 253: 'from',\n",
       " 254: 'notes',\n",
       " 255: '1980s',\n",
       " 256: 'abound',\n",
       " 257: 'vocals',\n",
       " 258: 'communities'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create index2word dictionary\n",
    "#2 min    \n",
    "index2word = {v:k for k, v in word2index.items()}\n",
    "\n",
    "index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68360563-66c4-40ec-a56a-f751caf58a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'Jazz',\n",
       " 'tradition',\n",
       " 'biguine',\n",
       " 'do',\n",
       " 'big',\n",
       " 'or',\n",
       " 'Louisiana',\n",
       " '1860',\n",
       " 'rhythm',\n",
       " '1910s',\n",
       " 'league',\n",
       " 'dance',\n",
       " 'smooth',\n",
       " 'quadrilles',\n",
       " 'As',\n",
       " 'late',\n",
       " 'rituals',\n",
       " 'pitch',\n",
       " 'traditional',\n",
       " 'free',\n",
       " 'styles',\n",
       " 'described',\n",
       " 'cultures',\n",
       " 'bluesy',\n",
       " 'baseball',\n",
       " 'lines',\n",
       " 'harmony',\n",
       " 'introducing',\n",
       " 'pep',\n",
       " 'highly',\n",
       " 'different',\n",
       " 'style',\n",
       " 'musician',\n",
       " 'as',\n",
       " 'meter',\n",
       " 'improvisation',\n",
       " 'genre',\n",
       " 'meaning',\n",
       " 'French',\n",
       " 'that',\n",
       " 'complex',\n",
       " 'chord',\n",
       " 'end',\n",
       " 'saw',\n",
       " 'In',\n",
       " 'without',\n",
       " 'called',\n",
       " 'dating',\n",
       " 'played',\n",
       " 'structure',\n",
       " 'local',\n",
       " 'piano',\n",
       " 'instruments',\n",
       " 'Cool',\n",
       " 'small',\n",
       " 'Other',\n",
       " 'chords',\n",
       " 'simply',\n",
       " 'music',\n",
       " 'musical',\n",
       " 'swing',\n",
       " 'rise',\n",
       " 'Bebop',\n",
       " 'electric',\n",
       " 'elsewhere',\n",
       " 'successful',\n",
       " 'African',\n",
       " 'faster',\n",
       " 'recognized',\n",
       " 'The',\n",
       " 'appeared',\n",
       " 'the',\n",
       " 'emergence',\n",
       " 'arranged',\n",
       " '.',\n",
       " 'sounds',\n",
       " '1960s',\n",
       " 'Angeles',\n",
       " 'wobbles',\n",
       " 'shifting',\n",
       " 'tempos',\n",
       " 'sound',\n",
       " 'energy',\n",
       " 'musette',\n",
       " 'considerable',\n",
       " 'on',\n",
       " 'regional',\n",
       " 'earliest',\n",
       " ',',\n",
       " 'Cuban',\n",
       " 'minor',\n",
       " 'toward',\n",
       " 'stage',\n",
       " 'because',\n",
       " '(',\n",
       " \"'s\",\n",
       " 'ragtime.[1][2][3][4',\n",
       " 'begin',\n",
       " 'its',\n",
       " 'be',\n",
       " \"'\",\n",
       " 'melodic',\n",
       " '19th',\n",
       " 'which',\n",
       " 'fusion',\n",
       " '1930s',\n",
       " 'rhythms',\n",
       " '21st',\n",
       " 'Orleans',\n",
       " 'national',\n",
       " 'such',\n",
       " 'term',\n",
       " 'mode',\n",
       " 'to',\n",
       " 'combining',\n",
       " 'Afro',\n",
       " 'well',\n",
       " 'research',\n",
       " 'response',\n",
       " 'marches',\n",
       " 'believed',\n",
       " '1950s',\n",
       " 'major',\n",
       " 'developed',\n",
       " 'early',\n",
       " 'he',\n",
       " 'influences',\n",
       " 'ca',\n",
       " 'call',\n",
       " 'collective',\n",
       " 'swinging',\n",
       " 'Latin',\n",
       " 'Age',\n",
       " 'world',\n",
       " 'emphasized',\n",
       " 'saxophone',\n",
       " 'playing',\n",
       " 'rock',\n",
       " 'more',\n",
       " 'amplified',\n",
       " 'back',\n",
       " 'centuries',\n",
       " 'regular',\n",
       " 'record',\n",
       " 'spread',\n",
       " 'particularly',\n",
       " '1940s',\n",
       " 'anything',\n",
       " 'linear',\n",
       " 'brass',\n",
       " 'American',\n",
       " 'City',\n",
       " 'explored',\n",
       " 'commercial',\n",
       " 'significant',\n",
       " 'began',\n",
       " 'based',\n",
       " 'Since',\n",
       " 'formal',\n",
       " 'gave',\n",
       " 'bop',\n",
       " '1970s',\n",
       " 'characterized',\n",
       " 'around',\n",
       " 'drew',\n",
       " 'long',\n",
       " 'structures',\n",
       " 'waltzes',\n",
       " 'in',\n",
       " 'jasm',\n",
       " 'used',\n",
       " 'earlier',\n",
       " 'word',\n",
       " 'roots',\n",
       " 'gospel',\n",
       " 'you',\n",
       " 'using',\n",
       " 'not',\n",
       " 'basis',\n",
       " 'at',\n",
       " 'was',\n",
       " 'polyrhythms',\n",
       " '-',\n",
       " 'danceable',\n",
       " 'scale',\n",
       " 'is',\n",
       " 'been',\n",
       " 'smoother',\n",
       " ']',\n",
       " 'improvisational',\n",
       " 'written',\n",
       " 'with',\n",
       " 'and',\n",
       " 'rhythmic',\n",
       " '1920s',\n",
       " 'prominent',\n",
       " 'blue',\n",
       " 'expression',\n",
       " 'popular',\n",
       " 'resulted',\n",
       " 'slang',\n",
       " 'documented',\n",
       " 'hard',\n",
       " 'jazz',\n",
       " 'gypsy',\n",
       " 'European',\n",
       " 'groups',\n",
       " 'ragtime',\n",
       " 'century',\n",
       " 'originated',\n",
       " 'of',\n",
       " 'history',\n",
       " 'calmer',\n",
       " ')',\n",
       " 'became',\n",
       " \"n't\",\n",
       " 'blues',\n",
       " 'mid-1950s',\n",
       " 'introduced',\n",
       " 'were',\n",
       " 'article',\n",
       " '20th',\n",
       " 'It',\n",
       " 'has',\n",
       " 'by',\n",
       " 'did',\n",
       " 'radio',\n",
       " 'Modal',\n",
       " '1912',\n",
       " 'Los',\n",
       " 'a',\n",
       " 'emerged',\n",
       " 'challenging',\n",
       " 'origin',\n",
       " 'pitcher',\n",
       " 'bands',\n",
       " 'near',\n",
       " 'garnering',\n",
       " 'airplay',\n",
       " 'New',\n",
       " 'But',\n",
       " 'Kansas',\n",
       " 'genres',\n",
       " 'form',\n",
       " 'beat',\n",
       " 'polyphonic',\n",
       " 'band',\n",
       " 'related',\n",
       " 'Times',\n",
       " 'ball',\n",
       " 'oriented',\n",
       " 'single',\n",
       " 'from',\n",
       " 'notes',\n",
       " '1980s',\n",
       " 'abound',\n",
       " 'vocals',\n",
       " 'communities',\n",
       " '<UNK>']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8437181a-c68a-49b7-9979-2ac8bff613ca",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c284982-6105-4446-8c42-bc07ebd66cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'Jazz'],\n",
       " ['a', 'genre'],\n",
       " ['music', 'is'],\n",
       " ['music', 'that'],\n",
       " ['genre', 'a'],\n",
       " ['genre', 'originated'],\n",
       " ['that', 'music'],\n",
       " ['that', 'in'],\n",
       " ['originated', 'genre'],\n",
       " ['originated', 'the'],\n",
       " ['in', 'that'],\n",
       " ['in', 'African'],\n",
       " ['the', 'originated'],\n",
       " ['the', '-'],\n",
       " ['African', 'in'],\n",
       " ['African', 'American'],\n",
       " ['-', 'the'],\n",
       " ['-', 'communities'],\n",
       " ['American', 'African'],\n",
       " ['American', 'of'],\n",
       " ['communities', '-'],\n",
       " ['communities', 'New'],\n",
       " ['of', 'American'],\n",
       " ['of', 'Orleans'],\n",
       " ['New', 'communities'],\n",
       " ['New', ','],\n",
       " ['Orleans', 'of'],\n",
       " ['Orleans', 'Louisiana'],\n",
       " [',', 'New'],\n",
       " [',', ',']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#use window_size = 2 as the assignment's instruction.\n",
    "\n",
    "skipgrams = []\n",
    "\n",
    "#for each corpus\n",
    "for sent in corpus_tokenized:\n",
    "    for i in range(2, len(sent)-2): #start from 2 to second last\n",
    "        center_word = sent[i]\n",
    "        outside_words = [sent[i-2], sent[i+2]]  #window_size = 2\n",
    "        for o in outside_words:\n",
    "            skipgrams.append([center_word, o])\n",
    "\n",
    "skipgrams[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "817a007c-122b-4b1e-b8fa-22ffc0a74075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's make what we have made into a function (batch function)\n",
    "#return a batches of data, e.g., =2 --> ['banana', 'apple'], ['banana', 'fruit']\n",
    "#also i want these batches to be id, NOT token   --> [5, 4]\n",
    "\n",
    "def random_batch(batch_size, corpus):\n",
    "    \n",
    "    skipgrams = []\n",
    "\n",
    "    #for each corpus\n",
    "    for sent in corpus_tokenized:\n",
    "        #for each sent \n",
    "        for i in range(2, len(sent) - 2): #start from 2 to the third last\n",
    "            center_word = word2index[sent[i]]\n",
    "            outside_words = [word2index[sent[i-2]], word2index[sent[i+2]]]  #window_size = 2\n",
    "            for o in outside_words:\n",
    "                skipgrams.append([center_word, o])\n",
    "                \n",
    "    #only get a batch, not the entire list\n",
    "    random_index = np.random.choice(range(len(skipgrams)), batch_size, replace=False)\n",
    "             \n",
    "    #appending some list of inputs and labels\n",
    "    random_inputs, random_labels = [], []   \n",
    "    for index in random_index:\n",
    "        random_inputs.append([skipgrams[index][0]])  #center words, this will be a shape of (1, ) --> (1, 1) for modeling\n",
    "        random_labels.append([skipgrams[index][1]])\n",
    "        \n",
    "    return np.array(random_inputs), np.array(random_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b908f760-93dc-482d-84e9-b9183cfaa3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n",
      "label=array([[ 59],\n",
      "       [186],\n",
      "       [174],\n",
      "       [ 18],\n",
      "       [ 92],\n",
      "       [ 89],\n",
      "       [ 80],\n",
      "       [238],\n",
      "       [ 23],\n",
      "       [ 96]])\n"
     ]
    }
   ],
   "source": [
    "input, label = random_batch(10, corpus_tokenized)\n",
    "\n",
    "print(f\"{input.shape}\")\n",
    "print(f\"{label=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adcd33d-597c-47b2-aea1-6c304060b21d",
   "metadata": {},
   "source": [
    "## Unigram distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "378a3eb2-7129-4be9-acd8-0216dc9deb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_count = Counter(flatten(corpus_tokenized))\n",
    "# word_count # Showing word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b097d1d-dad9-4500-920b-1c5cb4c4f40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_total_words = sum([c for w, c in word_count.items()])\n",
    "num_total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "265b4424-a2a1-439d-933b-98acc35725b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 0.001  #scaling up low frequency terms\n",
    "unigram_table = []\n",
    "\n",
    "# create loop for the P(w) formula\n",
    "for v in vocabs:\n",
    "    uw = word_count[v]/num_total_words\n",
    "    uw_alpha = uw ** (3/4)\n",
    "    uw_alpha_dividebyz = int(uw_alpha / z)\n",
    "    unigram_table.extend([v] * uw_alpha_dividebyz)\n",
    "    \n",
    "# Counter(unigram_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7074cd7-d4a8-4d87-9567-968e6d0c5bbb",
   "metadata": {},
   "source": [
    "## 4. Negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fb9f05e-2453-4ce0-85e2-44ebdcf3ec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, word2index):\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return torch.LongTensor(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f15dc315-7da2-4a0f-a837-a1e5191be6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def negative_sampling(targets, unigram_table, k):\n",
    "    \n",
    "    batch_size = targets.shape[0]\n",
    "    neg_samples = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        #randomly pick k negative words from unigram_table\n",
    "        target_index = targets[i].item()  #looping each of the batch....\n",
    "        nsample = []\n",
    "        while len(nsample) < k:\n",
    "            neg = random.choice(unigram_table)\n",
    "            #if this word == target, skip this word\n",
    "            if word2index[neg] == target_index:\n",
    "                continue\n",
    "            nsample.append(neg)\n",
    "        #append this word to some list\n",
    "        neg_samples.append(prepare_sequence(nsample, word2index).reshape(1, -1))  #tensor[], tensor[]\n",
    "    return torch.cat(neg_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e555fde6-dcee-45ff-83be-00d23f13ee77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 60],\n",
       "        [126]]),\n",
       " array([[244],\n",
       "        [231]]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "input_batch, label_batch = random_batch(batch_size, corpus_tokenized)\n",
    "\n",
    "input_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42140165-ad66-4045-8b11-db3582ec66a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Tensor\n",
    "\n",
    "input_batch = torch.LongTensor(input_batch)\n",
    "label_batch = torch.LongTensor(label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "956cce9f-ed10-4527-bad5-8832d3e9fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neg = 5 \n",
    "neg_samples = negative_sampling(label_batch, unigram_table, num_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "590a783e-66e4-4c8f-91c7-619a54dc6a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_samples.shape # shape is (batch_size, num_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c74a46-7732-41ac-9163-9dea8019a5af",
   "metadata": {},
   "source": [
    "## 5. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "433ca860-b78e-436a-8ebb-3e1f20b7a208",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipgramNeg(nn.Module):\n",
    "    \n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(SkipgramNeg, self).__init__()\n",
    "        self.embedding_center_word  = nn.Embedding(voc_size, emb_size)\n",
    "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
    "        self.logsigmoid = nn.LogSigmoid()\n",
    "        \n",
    "    def forward(self, centre_words, outside_words, negative_words):\n",
    "        #center_words, outside_words: (batch_size, 1)\n",
    "        #negative_words:  (batch_size, k)\n",
    "        \n",
    "        center_embbed  = self.embedding_center_word(centre_words)    #(batch_size, 1, emb_size)\n",
    "        outside_embbed = self.embedding_outside_word(outside_words)  #(batch_size, 1, emb_size)\n",
    "        neg_embbed     = self.embedding_outside_word(negative_words) #(batch_size, k, emb_size)\n",
    "        \n",
    "        uovc          =  outside_embbed.bmm(center_embbed.transpose(1, 2)).squeeze(2)  #(batch_size, 1)\n",
    "        ukvc          = -neg_embbed.bmm(center_embbed.transpose(1, 2)).squeeze(2)  #(batch_size, k)\n",
    "        ukvc_sum      =  torch.sum(ukvc, 1).view(-1, 1) #(batch_size, 1)\n",
    "        \n",
    "        loss = self.logsigmoid(uovc) + self.logsigmoid(ukvc_sum)  #(batch_size, 1) + (batch_size, 1)\n",
    "                \n",
    "        return -torch.mean(loss)  \n",
    "#scalar, loss should be scalar, to call backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "514aa4ac-f691-43d7-8efb-8f25d0373c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "input, label = random_batch(batch_size, corpus_tokenized)\n",
    "input_tensor = torch.LongTensor(input)  \n",
    "label_tensor = torch.LongTensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd75b1c9-4e11-46fd-a02c-294cc3adcc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 20 \n",
    "voc_size = len(vocabs)\n",
    "model = SkipgramNeg(voc_size, emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0952176c-3380-4e8e-bf0b-2f16104fce06",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_tensor = negative_sampling(label_tensor, unigram_table, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d0d0e68-5400-4008-ad7c-40dbc2fe4824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[219, 109, 104, 195, 211],\n",
       "        [219,  27, 217, 181, 129]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ac25dc18-1e28-419c-be71-f2f2ecb3abec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1]), torch.Size([2, 1]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape, label_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4e12ad3-ca64-490d-90e6-661ec57319c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.3403, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = model(input_tensor, label_tensor, neg_tensor)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea57919-f10e-4951-a0fb-ef73a4afa826",
   "metadata": {},
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3c0f437-de6c-4105-bccf-ff121dea89c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size   = len(vocabs)\n",
    "batch_size = 2\n",
    "emb_size   = 20\n",
    "model      = SkipgramNeg(voc_size, emb_size)\n",
    "\n",
    "optimizer  = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc1edbc6-742f-4c2c-8692-8d8d36e9836e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 | Loss: -0.000000 | Time: 0mins 0secs\n",
      "Epoch 2000 | Loss: 0.417835 | Time: 0mins 0secs\n",
      "Epoch 3000 | Loss: -0.000000 | Time: 0mins 0secs\n",
      "Epoch 4000 | Loss: -0.000000 | Time: 0mins 0secs\n",
      "Epoch 5000 | Loss: -0.000000 | Time: 0mins 0secs\n",
      "Epoch 6000 | Loss: -0.000000 | Time: 0mins 0secs\n",
      "Process Time: 0mins 13secs\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 6000\n",
    "start0 = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    #get random batch\n",
    "    start = time.time()\n",
    "    input_batch, label_batch = random_batch(batch_size, corpus_tokenized)\n",
    "    input_batch = torch.LongTensor(input_batch)\n",
    "    label_batch = torch.LongTensor(label_batch)\n",
    "    neg_batch   = negative_sampling(label_batch, unigram_table, 5)    \n",
    "    \n",
    "    #loss = model\n",
    "    loss = model(input_batch, label_batch, neg_batch)\n",
    "    end = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
    "    \n",
    "    #backpropagate\n",
    "    loss.backward()\n",
    "    \n",
    "    #update alpha\n",
    "    optimizer.step()\n",
    "    \n",
    "    #print epoch loss\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch {epoch+1} | Loss: {loss:.6f} | Time: {epoch_mins}mins {epoch_secs}secs\")\n",
    "end0 = time.time()\n",
    "mins, secs = epoch_time(start0, end0)\n",
    "print(f\"Process Time: {mins}mins {secs}secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa39269b-d3b3-4af5-90ed-6abaa1544017",
   "metadata": {},
   "source": [
    "## 7. Plot the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "223716df-24cc-487f-b4d8-6665e7e4cc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([204])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jazz = torch.LongTensor([word2index['jazz']])\n",
    "jazz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "de35d922-c0ed-40a2-a9cc-ba3576998f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([53])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruments = torch.LongTensor([word2index['instruments']])\n",
    "instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ffd92052-299e-45e4-8681-508e1f0d9f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3223,  1.0966, -1.9764,  2.4778, 12.6112, -7.2821,  1.2553,  1.2708,\n",
       "         -2.5595,  1.2265,  1.6928,  6.3198,  2.5363,  9.4691,  8.1073, -6.0183,\n",
       "         -0.1430,  7.5450,  2.2697, -2.1826]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jazz_center_embbed = model.embedding_center_word(jazz)\n",
    "jazz_outside_embbed = model.embedding_outside_word(jazz)\n",
    "jazz_embbed = (jazz_center_embbed + jazz_outside_embbed) / 2\n",
    "jazz_embbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "673eb362-ce83-4e98-b170-46d289437707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embbed(word):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except:\n",
    "        index = word2index['<UNK>']\n",
    "    \n",
    "    word = torch.LongTensor([index])\n",
    "\n",
    "    center_embbed  = model.embedding_center_word(word)\n",
    "    outside_embbed = model.embedding_outside_word(word)\n",
    "    \n",
    "    embbed = (center_embbed + outside_embbed) / 2\n",
    "    \n",
    "    return  embbed[0][0].item(), embbed[0][1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ae29d034-9ea0-48ca-ab7c-5366432f0364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.32233959436416626, 1.0966049432754517)\n"
     ]
    }
   ],
   "source": [
    "print(get_embbed('jazz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d1cb9376-5b49-4a8e-b273-f77056eb144f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "for i, word in enumerate(vocabs[:20]): #loop each unique vocab\n",
    "    x, y = get_embbed(word)\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6a9424-e542-441d-a78d-f06c4c1fa00c",
   "metadata": {},
   "source": [
    "## Try CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ff285977-0147-4bec-97c2-5e5797938f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete duplicate word define as vocabs, also include unknow as <UNK>.\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "vocabs  = list(set(flatten(corpus_tokenized)))\n",
    "vocabs.append('<UNK>') # to let '<UNK>' become the last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b976be00-1b73-4d46-bae7-562c3a9149e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index = {v: idx+1 for idx, v in enumerate(vocabs)} #plus one to shift value in word index to assign <UNK>'s value to 0 without duplication with others.\n",
    "word2index['<UNK>'] = 0\n",
    "\n",
    "#Let check word to index's value\n",
    "word2index[\"jazz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d774c2bc-5e11-4a8a-b960-b02a889f0c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'African'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create index to word\n",
    "index2word = {v:k for k, v in word2index.items()}\n",
    "\n",
    "index2word[68]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559b0f14-1745-4e2a-b68a-44ea607457d1",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7b3fd8da-d2af-47b8-ba93-89024ba6811d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'do'],\n",
       " ['a', '.'],\n",
       " ['music', 'do'],\n",
       " ['music', '.'],\n",
       " ['genre', 'do'],\n",
       " ['genre', '.'],\n",
       " ['that', 'do'],\n",
       " ['that', '.'],\n",
       " ['originated', 'do'],\n",
       " ['originated', '.'],\n",
       " ['in', 'do'],\n",
       " ['in', '.'],\n",
       " ['the', 'do'],\n",
       " ['the', '.'],\n",
       " ['African', 'do'],\n",
       " ['African', '.'],\n",
       " ['-', 'do'],\n",
       " ['-', '.'],\n",
       " ['American', 'do'],\n",
       " ['American', '.'],\n",
       " ['communities', 'do'],\n",
       " ['communities', '.'],\n",
       " ['of', 'do'],\n",
       " ['of', '.'],\n",
       " ['New', 'do'],\n",
       " ['New', '.'],\n",
       " ['Orleans', 'do'],\n",
       " ['Orleans', '.'],\n",
       " [',', 'do'],\n",
       " [',', '.']]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow = []\n",
    "\n",
    "#for each corpus\n",
    "for sent in corpus_tokenized:\n",
    "    #for each sent \n",
    "    for i in range(2, len(sent) - 2): # start from 1 to second last but we use window size of 2, then first centre word should be at index 2\n",
    "        center_word = sent[i]\n",
    "        ooutside_words = [sent[i-2], sent[i+2]]  #window_size = 2\n",
    "        for o in outside_words:\n",
    "            cbow.append([center_word, o])\n",
    "\n",
    "cbow[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "31a1c63b-3c1a-4f5a-b67e-0022b86d1f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(batch_size, corpus):\n",
    "    \n",
    "    cbow = []\n",
    "\n",
    "    #for each corpus\n",
    "    for sent in corpus_tokenized:\n",
    "        #for each sent \n",
    "        for i in range(2, len(sent) - 2): #start from 2 to the third last\n",
    "            center_word = word2index[sent[i]]\n",
    "            outside_words = [word2index[sent[i-2]], word2index[sent[i+2]]]  #window_size = 2\n",
    "            for o in outside_words:\n",
    "                cbow.append([center_word, o])\n",
    "                \n",
    "    #only get a batch, not the entire list\n",
    "    random_index = np.random.choice(range(len(skipgrams)), batch_size, replace=False)\n",
    "             \n",
    "    #appending some list of inputs and labels\n",
    "    random_inputs, random_labels = [], []   \n",
    "    for index in random_index:\n",
    "        random_inputs.append([cbow[index][0]])  \n",
    "        random_labels.append([cbow[index][1]])\n",
    "        \n",
    "    return np.array(random_inputs), np.array(random_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "233d4ea0-3852-4ab1-9085-61b9e8efb4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n",
      "label=array([[139],\n",
      "       [ 69],\n",
      "       [ 37],\n",
      "       [ 92],\n",
      "       [  7],\n",
      "       [232],\n",
      "       [ 90],\n",
      "       [ 73],\n",
      "       [221],\n",
      "       [ 85]])\n"
     ]
    }
   ],
   "source": [
    "input, label = random_batch(10, corpus_tokenized)\n",
    "\n",
    "print(f\"{input.shape}\")\n",
    "print(f\"{label=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3ef726-fa46-4fd0-95e5-e714bc6b1623",
   "metadata": {},
   "source": [
    "## Unigram distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "639e925f-e55b-4def-8795-653eb748ddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_count = Counter(flatten(corpus_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ebb7be50-8a40-48ab-8e47-cf8920ab516a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_total_words = sum([c for w, c in word_count.items()])\n",
    "num_total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "df391a31-805d-4f57-9cb4-733a4b79a2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 0.001  #scaling up low frequency terms\n",
    "unigram_table = []\n",
    "\n",
    "# create loop for the P(w) formula\n",
    "for v in vocabs:\n",
    "    uw = word_count[v]/num_total_words\n",
    "    uw_alpha = uw ** (3/4)\n",
    "    uw_alpha_dividebyz = int(uw_alpha / z)\n",
    "    unigram_table.extend([v] * uw_alpha_dividebyz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a612a706-ff7d-40a7-9fde-9ba7c970f33e",
   "metadata": {},
   "source": [
    "## Negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eb1a6669-0c66-4ae3-a127-867e83554174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, word2index):\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return torch.LongTensor(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4f421c88-0742-400e-a73b-c4bd72538bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def negative_sampling(targets, unigram_table, k):\n",
    "    \n",
    "    batch_size = targets.shape[0]\n",
    "    neg_samples = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        #randomly pick k negative words from unigram_table\n",
    "        target_index = targets[i].item()  #looping each of the batch....\n",
    "        nsample = []\n",
    "        while len(nsample) < k:\n",
    "            neg = random.choice(unigram_table)\n",
    "            #if this word == target, skip this word\n",
    "            if word2index[neg] == target_index:\n",
    "                continue\n",
    "            nsample.append(neg)\n",
    "        #append this word to some list\n",
    "        neg_samples.append(prepare_sequence(nsample, word2index).reshape(1, -1))  #tensor[], tensor[]\n",
    "    return torch.cat(neg_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b013face-fc57-463b-a4e5-95d8234b0a28",
   "metadata": {},
   "source": [
    "Skipgram and CBOW have different prediction methods\n",
    "then it has to flip labels and inputs for CBOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cd371d58-1481-4af0-a4e9-edf2ee93a0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[200],\n",
       "        [ 73]]),\n",
       " array([[ 93],\n",
       "        [222]]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "label_batch, input_batch = random_batch(batch_size, corpus_tokenized)\n",
    "\n",
    "input_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a881ce9b-0bb7-47e4-a80a-5e0ed768d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Tensor\n",
    "\n",
    "input_batch = torch.LongTensor(input_batch)\n",
    "label_batch = torch.LongTensor(label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5e3d2c6d-6c13-466f-b145-8f8439977783",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neg = 5  # same as the first part\n",
    "neg_samples = negative_sampling(label_batch, unigram_table, num_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "95a58168-a389-409b-8b0d-9634f18ef81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_samples.shape # shape is (batch_size, num_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3198b611-aea9-4b8c-83a5-f4280c319c12",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5f3a1a9c-3f85-4f1b-98a0-6bb04ea780e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I took this from https://github.com/jeffchy/pytorch-word-embedding/blob/master/CBOW.py\n",
    "\n",
    "class cbow(nn.Module):\n",
    "    \n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(cbow, self).__init__()\n",
    "        self.embedding_center_word  = nn.Embedding(voc_size, emb_size)\n",
    "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
    "        self.logsigmoid = nn.LogSigmoid()\n",
    "        \n",
    "    def forward(self, center_words, outside_words, negative_words):\n",
    "        \n",
    "        center_embed  = self.embedding_center_word(center_words)    #(batch_size, 1, emb_size)\n",
    "        outside_embed = self.embedding_outside_word(outside_words)  #(batch_size, 1, emb_size)\n",
    "        neg_embed     = self.embedding_outside_word(negative_words) #(batch_size, k, emb_size)\n",
    "        \n",
    "        uovc          =  outside_embed.bmm(center_embed.transpose(1, 2)).squeeze(2)  #(batch_size, 1)\n",
    "        ukvc          = -neg_embed.bmm(center_embed.transpose(1, 2)).squeeze(2)  #(batch_size, k)\n",
    "        ukvc_sum      =  torch.sum(ukvc, 1).view(-1, 1) #(batch_size, 1)\n",
    "        \n",
    "        loss = self.logsigmoid(uovc) + self.logsigmoid(ukvc_sum)  #(batch_size, 1) + (batch_size, 1)\n",
    "                \n",
    "        return -torch.mean(loss)  #scalar, loss should be scalar, to call backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "86fbc226-7512-4429-8241-bada6a159c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "label, input = random_batch(batch_size, corpus_tokenized)\n",
    "input_tensor = torch.LongTensor(input)  \n",
    "label_tensor = torch.LongTensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ae6fa688-3e89-4f76-8373-77a3b864e57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 20 # I will try on 10.\n",
    "voc_size = len(vocabs)\n",
    "model = cbow(voc_size, emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3eead5e3-9a8b-4f30-a486-7de1e6754f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "51756e65-75b0-406c-9582-af5a7f2a1279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dba4dfab-8e6c-4cee-b744-f013fce7356c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cbow(\n",
       "  (embedding_center_word): Embedding(260, 20)\n",
       "  (embedding_outside_word): Embedding(260, 20)\n",
       "  (logsigmoid): LogSigmoid()\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a446cb7e-80f6-47f7-bef1-876a9e607c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_tensor = negative_sampling(label_tensor, unigram_table, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a7be2f30-e199-427f-871e-2c976764c77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1]), torch.Size([2, 1]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape, label_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3d7db951-28f8-48d7-b1b4-61fa32660f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6110, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = model(input_tensor, label_tensor, neg_tensor)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680499e5-8f01-4a7e-8eeb-fa884b0df4c5",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "ae69955a-3ec3-4358-9805-ef9e62679619",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size   = len(vocabs)\n",
    "batch_size = 2\n",
    "emb_size   = 20\n",
    "model      = cbow(voc_size, emb_size)\n",
    "\n",
    "optimizer  = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a31d37b1-67f8-4196-85b4-dc0d92607d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 | Loss: 4.111963 | Time: 0mins 0secs\n",
      "Epoch 2000 | Loss: 6.369869 | Time: 0mins 0secs\n",
      "Epoch 3000 | Loss: 5.101603 | Time: 0mins 0secs\n",
      "Epoch 4000 | Loss: 6.399364 | Time: 0mins 0secs\n",
      "Epoch 5000 | Loss: 1.377746 | Time: 0mins 0secs\n",
      "Epoch 6000 | Loss: 5.358601 | Time: 0mins 0secs\n",
      "Process Time: 0mins 13secs\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 6000\n",
    "start0 = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    #get random batch\n",
    "    input_batch, label_batch = random_batch(batch_size, corpus_tokenized)\n",
    "    input_batch = torch.LongTensor(input_batch)\n",
    "    label_batch = torch.LongTensor(label_batch)\n",
    "    neg_batch   = negative_sampling(label_batch, unigram_table, 5)    \n",
    "    \n",
    "    #loss = model\n",
    "    loss = model(input_batch, label_batch, neg_batch)\n",
    "    end = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
    "    \n",
    "    #backpropagate\n",
    "    loss.backward()\n",
    "    \n",
    "    #update alpha\n",
    "    optimizer.step()\n",
    "    \n",
    "    #print epoch loss\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch {epoch+1} | Loss: {loss:.6f} | Time: {epoch_mins}mins {epoch_secs}secs\")\n",
    "end0 = time.time()\n",
    "mins, secs = epoch_time(start0, end0)\n",
    "print(f\"Process Time: {mins}mins {secs}secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c921f25-43dd-4501-afe7-512b36b41382",
   "metadata": {},
   "source": [
    "## Plot the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ec280945-82cb-4a68-80cc-9ffe6c7cf50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([205])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jazz = torch.LongTensor([word2index['jazz']])\n",
    "jazz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "279d4fb0-756f-4353-9958-1ef0ae78a745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.5448e-01,  2.2758e-01, -6.9176e-01,  1.1438e+00,  7.2603e-01,\n",
       "         -7.2409e-01,  3.1706e-02,  5.4285e-01, -2.7305e-01, -1.8061e+00,\n",
       "         -1.0802e+00, -4.8101e-04, -4.6763e-01, -3.6018e-01,  1.6936e+00,\n",
       "         -4.6324e-01, -2.0390e-01, -1.0038e+00,  1.1910e+00, -2.4377e-02]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jazz_center_embed = model.embedding_center_word(jazz)\n",
    "jazz_outside_embed = model.embedding_outside_word(jazz)\n",
    "\n",
    "jazz_embed = (jazz_center_embed + jazz_outside_embed) / 2\n",
    "jazz_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7e039e1d-20c6-40d4-ac2c-ea598b8e650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed(word):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except:\n",
    "        index = word2index['<UNK>']\n",
    "    \n",
    "    word = torch.LongTensor([index])\n",
    "\n",
    "    center_embed  = model.embedding_center_word(word)\n",
    "    outside_embed = model.embedding_outside_word(word)\n",
    "    \n",
    "    embed = (center_embed + outside_embed) / 2\n",
    "    \n",
    "    return  embed[0][0].item(), embed[0][1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6a474693-0d71-4064-b26f-a411f4d9d145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.4544777274131775, 0.2275848388671875)\n"
     ]
    }
   ],
   "source": [
    "print(get_embed('jazz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7da8971b-f31f-407c-9d86-024478db903d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "for i, word in enumerate(vocabs[:20]): #loop each unique vocab\n",
    "    x, y = get_embed(word)\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf01f2-7a2e-49d3-bdfa-ec6006bde0ea",
   "metadata": {},
   "source": [
    "## Try Normal Skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f77a238b-84bf-4efb-9dc7-e3812833dc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#delete duplicate word define as vocabs, also include unknow as <UNK>.\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "vocabs  = list(set(flatten(corpus_tokenized)))\n",
    "vocabs.append('<UNK>') # to let '<UNK>' become the last.\n",
    "word2index = {v: idx+1 for idx, v in enumerate(vocabs)} #plus one to shift value in word index to assign <UNK>'s value to 0 without duplication with others.\n",
    "word2index['<UNK>'] = 0\n",
    "\n",
    "#Let check word to index's value\n",
    "word2index[\"jazz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "db458481-af57-4143-b98e-4cc1c18b2d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wobbles'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create index to word\n",
    "index2word = {v:k for k, v in word2index.items()}\n",
    "\n",
    "index2word[80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "727b4e62-8d34-4b56-a5f5-f934a2fc5e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgrams = []\n",
    "\n",
    "#for each corpus\n",
    "for sent in corpus_tokenized:\n",
    "    \n",
    "    for i in range(2, len(sent) - 2): # start from 1 to second last but we use window size of 2, then first centre word should be at index 2\n",
    "        center_word = sent[i]\n",
    "        outside_words = np.ravel([sent[i - 2:i],sent[i+1: i + 3]])  # window_size = 2\n",
    "        for o in outside_words:\n",
    "            skipgrams.append([center_word, o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c8dd80a7-eb61-4da2-b4b9-fb1e9cedcf7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'Jazz'],\n",
       " ['a', 'is'],\n",
       " ['a', 'music'],\n",
       " ['a', 'genre'],\n",
       " ['music', 'is'],\n",
       " ['music', 'a'],\n",
       " ['music', 'genre'],\n",
       " ['music', 'that'],\n",
       " ['genre', 'a'],\n",
       " ['genre', 'music'],\n",
       " ['genre', 'that'],\n",
       " ['genre', 'originated'],\n",
       " ['that', 'music'],\n",
       " ['that', 'genre'],\n",
       " ['that', 'originated'],\n",
       " ['that', 'in'],\n",
       " ['originated', 'genre'],\n",
       " ['originated', 'that'],\n",
       " ['originated', 'in'],\n",
       " ['originated', 'the'],\n",
       " ['in', 'that'],\n",
       " ['in', 'originated'],\n",
       " ['in', 'the'],\n",
       " ['in', 'African'],\n",
       " ['the', 'originated'],\n",
       " ['the', 'in'],\n",
       " ['the', 'African'],\n",
       " ['the', '-'],\n",
       " ['African', 'in'],\n",
       " ['African', 'the']]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipgrams[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e68bd830-3229-4dc6-bf1d-a1ad66ffb00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(batch_size, corpus):\n",
    "    \n",
    "    skipgrams = []\n",
    "\n",
    "    #for each corpus\n",
    "    for sent in corpus_tokenized:\n",
    "        #for each sent \n",
    "        for i in range(2, len(sent) - 2): #start from 2 to the third last\n",
    "            center_word = word2index[sent[i]]\n",
    "            outside_words = [word2index[sent[i-2]], word2index[sent[i+2]]]  #window_size = 2\n",
    "            for o in outside_words:\n",
    "                skipgrams.append([center_word, o])\n",
    "                \n",
    "    #only get a batch, not the entire list\n",
    "    random_index = np.random.choice(range(len(skipgrams)), batch_size, replace=False)\n",
    "             \n",
    "    #appending some list of inputs and labels\n",
    "    random_inputs, random_labels = [], []   \n",
    "    for index in random_index:\n",
    "        random_inputs.append([skipgrams[index][0]])  \n",
    "        random_labels.append([skipgrams[index][1]])\n",
    "        \n",
    "    return np.array(random_inputs), np.array(random_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d3e786aa-e07f-45c3-a439-be511492bc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skipgram(nn.Module):\n",
    "    \n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(Skipgram, self).__init__()\n",
    "        self.embedding_center_word  = nn.Embedding(voc_size, emb_size)  #is a lookup table mapping all ids in voc_size, into some vector of size emb_size\n",
    "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
    "    \n",
    "    def forward(self, center_word, outside_word, all_vocabs):\n",
    "        #center_word, outside_word: (batch_size, 1)\n",
    "        #all_vocabs: (batch_size, voc_size)\n",
    "        \n",
    "        #convert them into embedding\n",
    "        center_word_embed  = self.embedding_center_word(center_word)     #(batch_size, 1, emb_size)\n",
    "        outside_word_embed = self.embedding_outside_word(outside_word)   #(batch_size, 1, emb_size)\n",
    "        all_vocabs_embed   = self.embedding_outside_word(all_vocabs)     #(batch_size, voc_size, emb_size)\n",
    "        \n",
    "        #bmm is basically @ or .dot , but across batches (i.e., ignore the batch dimension)\n",
    "        top_term = outside_word_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
    "        #(batch_size, 1, emb_size) @ (batch_size, emb_size, 1) = (batch_size, 1, 1) ===> (batch_size, 1)\n",
    "        \n",
    "        top_term_exp = torch.exp(top_term)  #exp(uo vc)\n",
    "        #(batch_size, 1)\n",
    "        \n",
    "        lower_term = all_vocabs_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
    "         #(batch_size, voc_size, emb_size) @ (batch_size, emb_size, 1) = (batch_size, voc_size, 1) = (batch_size, voc_size)\n",
    "         \n",
    "        lower_term_sum = torch.sum(torch.exp(lower_term), 1) #sum exp(uw vc)\n",
    "        #(batch_size, 1)\n",
    "        \n",
    "        loss_fn = -torch.mean(torch.log(top_term_exp / lower_term_sum))\n",
    "        #(batch_size, 1) / (batch_size, 1) ==mean==> scalar\n",
    "        \n",
    "        return loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "66872fc5-1d01-432c-ad0f-d8aae3d8bb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n",
      "label=array([[  2],\n",
      "       [ 75],\n",
      "       [ 51],\n",
      "       [ 90],\n",
      "       [  5],\n",
      "       [170],\n",
      "       [254],\n",
      "       [129],\n",
      "       [ 90],\n",
      "       [205]])\n"
     ]
    }
   ],
   "source": [
    "input, label = random_batch(10, corpus_tokenized)\n",
    "\n",
    "print(f\"{input.shape}\")\n",
    "print(f\"{label=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17ca36a-61c7-40c5-b519-5620ba6528e7",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d9138230-d09f-4f70-b976-9deb3cb336bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 260])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "\n",
    "def prepare_sequence(seq, word2index):\n",
    "    #map(function, list of something)\n",
    "    #map will look at each of element in this list, and apply this function\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return torch.LongTensor(idxs)\n",
    "\n",
    "all_vocabs = prepare_sequence(list(vocabs), word2index).expand(batch_size, voc_size)\n",
    "all_vocabs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6d76e82a-d24a-444a-9d3c-94bd39568a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input, label = random_batch(batch_size, corpus_tokenized)\n",
    "input_tensor = torch.LongTensor(input)  \n",
    "label_tensor = torch.LongTensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8f3b1ae2-9419-4a29-99c7-0f7b08a106f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 20\n",
    "voc_size = len(vocabs)\n",
    "model = Skipgram(voc_size, emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "afeab875-8507-456b-ba0a-815b2a07a91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "52f63cc0-cba6-4225-9308-322f9460993a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "451118c1-c9c7-4ca2-9745-b86b1d4ea1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.2676, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = model(input_tensor, label_tensor, all_vocabs)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb15878f-25cd-4fe9-891e-386296b60580",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "50048ce9-d8b8-4269-8e41-b7f46aab65f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size   = len(vocabs)\n",
    "batch_size = 2\n",
    "emb_size   = 20\n",
    "model      = Skipgram(voc_size, emb_size)\n",
    "optimizer  = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "344bcd0b-440b-4dec-a553-5743520bbe42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 | Loss: 3.972332 | Time: 0mins 0secs\n",
      "Epoch 2000 | Loss: 8.093463 | Time: 0mins 0secs\n",
      "Epoch 3000 | Loss: 2.263709 | Time: 0mins 0secs\n",
      "Epoch 4000 | Loss: nan | Time: 0mins 0secs\n",
      "Epoch 5000 | Loss: nan | Time: 0mins 0secs\n",
      "Epoch 6000 | Loss: nan | Time: 0mins 0secs\n",
      "Process Time: 0mins 13secs\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 6000\n",
    "start0 = time.time()\n",
    "\n",
    "#for epoch\n",
    "for epoch in range(num_epochs):\n",
    "    start = time.time()\n",
    "    \n",
    "    #get random batch\n",
    "    input_batch, label_batch = random_batch(batch_size, corpus_tokenized)\n",
    "    input_batch = torch.LongTensor(input_batch)\n",
    "    label_batch = torch.LongTensor(label_batch)\n",
    "    \n",
    "    # print(input_batch.shape, label_batch.shape, all_vocabs.shape)\n",
    "    \n",
    "    #loss = model\n",
    "    loss = model(input_batch, label_batch, all_vocabs)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
    "    \n",
    "    #backpropagate\n",
    "    loss.backward()\n",
    "    \n",
    "    #update alpha\n",
    "    optimizer.step()\n",
    "    \n",
    "    #print epoch loss\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch {epoch+1} | Loss: {loss:.6f} | Time: {epoch_mins}mins {epoch_secs}secs\")\n",
    "\n",
    "end0 = time.time()\n",
    "mins, secs = epoch_time(start0, end0)\n",
    "print(f\"Process Time: {mins}mins {secs}secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7402a9-f005-493d-9aa4-931ea52819b0",
   "metadata": {},
   "source": [
    "## Plot the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d77c914d-4992-4c66-8e23-aa4c4f397f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([205])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jazz = torch.LongTensor([word2index['jazz']])\n",
    "jazz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ce78b38c-f606-476c-8816-04caf27fb74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jazz_center_embed = model.embedding_center_word(jazz)\n",
    "jazz_outside_embed = model.embedding_outside_word(jazz)\n",
    "\n",
    "jazz_embed = (jazz_center_embed + jazz_outside_embed) / 2\n",
    "jazz_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "cfb3fe7d-b8ac-45e8-89c4-5fe24c7d9f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed(word):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except:\n",
    "        index = word2index['<UNK>']\n",
    "    \n",
    "    word = torch.LongTensor([index])\n",
    "\n",
    "    center_embed  = model.embedding_center_word(word)\n",
    "    outside_embed = model.embedding_outside_word(word)\n",
    "    \n",
    "    embed = (center_embed + outside_embed) / 2\n",
    "    \n",
    "    return  embed[0][0].item(), embed[0][1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d84db4f3-2a15-4df1-8033-f91c3fb113eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(nan, nan)\n"
     ]
    }
   ],
   "source": [
    "print(get_embed('jazz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c5de6d4b-1317-4d9d-ae86-8d8f65ad3a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAADCCAYAAABE1cVRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAANIElEQVR4nO3d34tc533H8fenUkQJSZFdybasH5Wa6qJqKUQMwpBehPoHkmIsX/TChtTCuRCGGhza4CrVP+DE0BhTYSNSg0xcRCAJEUZBsd3c2vXKsWVURdFGJJUixVZy4QR8IUS+vdijst6MtLN7ZrW7ft4vOMyc5/mec74PA/rsnJlBqSokSe36o8VuQJK0uAwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGrVzsBuZjzZo1tXnz5sVuQ5KWlRMnTvy6qtbOHF+WQbB582YmJiYWuw1JWlaS/GLYuLeGJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNG0sQJNmZ5EySyST7h8wnybPd/Mkk22fMr0jy4yQvj6MfSdLoegdBkhXAQWAXsA14OMm2GWW7gK3dtg94bsb8E8Dpvr1IkuZuHO8IdgCTVXWuqq4AR4A9M2r2AC/WlNeB1UnWASTZAHwB+OYYepEkzdE4gmA9cH7a/oVubNSaZ4Angd+PoRdJ0hyNIwgyZKxGqUlyP/B+VZ2Y9SLJviQTSSYuX748nz4lSUOMIwguABun7W8ALo5Y8znggSQ/Z+qW0t8l+dawi1TVoaoaVNVg7dq1Y2hbkgTjCYI3ga1JtiRZBTwEHJ1RcxR4pPv20F3AB1V1qaq+WlUbqmpzd9x/VdUXx9CTJGlEK/ueoKquJnkcOA6sAF6oqlNJHuvmnweOAbuBSeBD4NG+15UkjUeqZt7OX/oGg0FNTEwsdhuStKwkOVFVg5nj/rJYkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXFjCYIkO5OcSTKZZP+Q+SR5tps/mWR7N74xyY+SnE5yKskT4+hHkjS63kGQZAVwENgFbAMeTrJtRtkuYGu37QOe68avAv9cVX8J3AX845BjJUkLaBzvCHYAk1V1rqquAEeAPTNq9gAv1pTXgdVJ1lXVpap6C6CqfgecBtaPoSdJ0ojGEQTrgfPT9i/wh/+Yz1qTZDPwWeCNMfQkSRrROIIgQ8ZqLjVJPgV8B/hyVf126EWSfUkmkkxcvnx53s1Kkj5qHEFwAdg4bX8DcHHUmiSfYCoEXqqq717vIlV1qKoGVTVYu3btGNqWJMF4guBNYGuSLUlWAQ8BR2fUHAUe6b49dBfwQVVdShLgP4DTVfVvY+hFkjRHK/ueoKquJnkcOA6sAF6oqlNJHuvmnweOAbuBSeBD4NHu8M8B/wC8m+Ttbuxfq+pY374kSaNJ1czb+UvfYDCoiYmJxW5DkpaVJCeqajBz3F8WS1LjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDVuLEGQZGeSM0kmk+wfMp8kz3bzJ5NsH/VYSdLC6h0ESVYAB4FdwDbg4STbZpTtArZ22z7guTkcK0laQON4R7ADmKyqc1V1BTgC7JlRswd4saa8DqxOsm7EYyVJC2gcQbAeOD9t/0I3NkrNKMcCkGRfkokkE5cvX+7dtCRpyjiCIEPGasSaUY6dGqw6VFWDqhqsXbt2ji1Kkq5n5RjOcQHYOG1/A3BxxJpVIxwrSVpA43hH8CawNcmWJKuAh4CjM2qOAo903x66C/igqi6NeKwkaQH1fkdQVVeTPA4cB1YAL1TVqSSPdfPPA8eA3cAk8CHw6I2O7duTJGl0qRp6S35JGwwGNTExsdhtSNKykuREVQ1mjvvLYklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNa5XECS5NckrSc52j7dcp25nkjNJJpPsnzb+dJKfJDmZ5HtJVvfpR5I0d33fEewHXquqrcBr3f5HJFkBHAR2AduAh5Ns66ZfAf66qv4G+Cnw1Z79SJLmqG8Q7AEOd88PAw8OqdkBTFbVuaq6AhzpjqOqflhVV7u614ENPfuRJM1R3yC4vaouAXSPtw2pWQ+cn7Z/oRub6UvAD3r2I0mao5WzFSR5FbhjyNSBEa+RIWM14xoHgKvASzfoYx+wD2DTpk0jXlqSNJtZg6Cq7rneXJL3kqyrqktJ1gHvDym7AGyctr8BuDjtHHuB+4G7q6q4jqo6BBwCGAwG162TJM1N31tDR4G93fO9wPeH1LwJbE2yJckq4KHuOJLsBP4FeKCqPuzZiyRpHvoGwVPAvUnOAvd2+yS5M8kxgO7D4MeB48Bp4NtVdao7/t+BTwOvJHk7yfM9+5EkzdGst4ZupKp+A9w9ZPwisHva/jHg2JC6v+hzfUlSf/6yWJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxvYIgya1JXklytnu85Tp1O5OcSTKZZP+Q+a8kqSRr+vQjSZq7vu8I9gOvVdVW4LVu/yOSrAAOAruAbcDDSbZNm98I3Av8b89eJEnz0DcI9gCHu+eHgQeH1OwAJqvqXFVdAY50x13zDeBJoHr2Ikmah75BcHtVXQLoHm8bUrMeOD9t/0I3RpIHgF9W1Ts9+5AkzdPK2QqSvArcMWTqwIjXyJCxSvLJ7hz3jXSSZB+wD2DTpk0jXlqSNJtZg6Cq7rneXJL3kqyrqktJ1gHvDym7AGyctr8BuAh8BtgCvJPk2vhbSXZU1a+G9HEIOAQwGAy8jSRJY9L31tBRYG/3fC/w/SE1bwJbk2xJsgp4CDhaVe9W1W1VtbmqNjMVGNuHhYAkaeH0DYKngHuTnGXqmz9PASS5M8kxgKq6CjwOHAdOA9+uqlM9rytJGpNZbw3dSFX9Brh7yPhFYPe0/WPAsVnOtblPL5Kk+fGXxZLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktS4VC2//wc+yWXgF4vdxzysAX692E3cRK2tF1xzK5brmv+sqtbOHFyWQbBcJZmoqsFi93GztLZecM2t+Lit2VtDktQ4g0CSGmcQ3FyHFruBm6y19YJrbsXHas1+RiBJjfMdgSQ1ziAYoyS3Jnklydnu8Zbr1O1McibJZJL9Q+a/kqSSrFn4rvvpu+YkTyf5SZKTSb6XZPVNa36ORnjdkuTZbv5kku2jHrtUzXfNSTYm+VGS00lOJXni5nc/P31e525+RZIfJ3n55nXdU1W5jWkDvg7s757vB742pGYF8DPgz4FVwDvAtmnzG4HjTP1OYs1ir2mh1wzcB6zsnn9t2PFLYZvtdetqdgM/AALcBbwx6rFLceu55nXA9u75p4GfftzXPG3+n4D/BF5e7PWMuvmOYLz2AIe754eBB4fU7AAmq+pcVV0BjnTHXfMN4ElguXx402vNVfXDqrra1b0ObFjYdudttteNbv/FmvI6sDrJuhGPXYrmveaqulRVbwFU1e+A08D6m9n8PPV5nUmyAfgC8M2b2XRfBsF43V5VlwC6x9uG1KwHzk/bv9CNkeQB4JdV9c5CNzpGvdY8w5eY+ktrKRplDderGXX9S02fNf+/JJuBzwJvjL/Fseu75meY+kPu9wvU34JYudgNLDdJXgXuGDJ1YNRTDBmrJJ/sznHffHtbKAu15hnXOABcBV6aW3c3zaxruEHNKMcuRX3WPDWZfAr4DvDlqvrtGHtbKPNec5L7gfer6kSSz4+7sYVkEMxRVd1zvbkk7117W9y9VXx/SNkFpj4HuGYDcBH4DLAFeCfJtfG3kuyoql+NbQHzsIBrvnaOvcD9wN3V3WRdgm64hllqVo1w7FLUZ80k+QRTIfBSVX13Afscpz5r/nvggSS7gT8G/iTJt6rqiwvY73gs9ocUH6cNeJqPfnD69SE1K4FzTP2jf+3DqL8aUvdzlseHxb3WDOwE/gdYu9hrmWWds75uTN0bnv4h4n/P5TVfalvPNQd4EXhmsddxs9Y8o+bzLKMPixe9gY/TBvwp8Bpwtnu8tRu/Ezg2rW43U9+i+Blw4DrnWi5B0GvNwCRT91vf7rbnF3tNN1jrH6wBeAx4rHse4GA3/y4wmMtrvhS3+a4Z+FumbqmcnPba7l7s9Sz06zztHMsqCPxlsSQ1zm8NSVLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhr3f2aEC85sOP5JAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "for i, word in enumerate(vocabs[:20]): #loop each unique vocab\n",
    "    x, y = get_embed(word)\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee51b63-6710-4dc5-a42d-31ee92843a85",
   "metadata": {},
   "source": [
    "From results of skipgram and negative samplings, there have 13 secs same as two methods. But I got problems about normal method that cannot reach 4000 epochs like the rest, maybe it has some limitations or my corpus is too small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4a106e-06cf-45bc-9520-29ae9c4ee5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
